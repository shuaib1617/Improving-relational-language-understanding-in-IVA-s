{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a16fd06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of CSV datasets in the directory is: 35\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set the directory path to the current working directory\n",
    "directory_path = os.getcwd()\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(directory_path)\n",
    "\n",
    "# Filter only CSV files\n",
    "csv_files = [file for file in files if file.endswith('.csv')]\n",
    "\n",
    "# Count the number of CSV files\n",
    "num_csv_files = len(csv_files)\n",
    "\n",
    "# Print the result\n",
    "print(f'The number of CSV datasets in the directory is: {num_csv_files}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aedb827d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files in the directory:\n",
      "1_1_align.csv\n",
      "1_2_align.csv\n",
      "1_3_align.csv\n",
      "1_4_align.csv\n",
      "2_1_align.csv\n",
      "2_2_align.csv\n",
      "2_3_align.csv\n",
      "2_4_align.csv\n",
      "3_1_align.csv\n",
      "3_2_align.csv\n",
      "3_3_align.csv\n",
      "3_4_align.csv\n",
      "4_1_align.csv\n",
      "4_2_align.csv\n",
      "4_3_align.csv\n",
      "4_4_align.csv\n",
      "5_1_align.csv\n",
      "5_2_align.csv\n",
      "5_3_align.csv\n",
      "5_4_align.csv\n",
      "6_1_align.csv\n",
      "6_2_align.csv\n",
      "6_3_align.csv\n",
      "6_4_align.csv\n",
      "7_1_align.csv\n",
      "7_2_align.csv\n",
      "7_3_align.csv\n",
      "7_4_align.csv\n",
      "8_1_align.csv\n",
      "8_2_align.csv\n",
      "8_3_align.csv\n",
      "8_4_align.csv\n",
      "all_data_by_threshold.csv\n",
      "all_multi_intent.csv\n",
      "tagged_selections_by_sentence.csv\n"
     ]
    }
   ],
   "source": [
    "# Set the directory path to the current working directory\n",
    "directory_path = os.getcwd()\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(directory_path)\n",
    "\n",
    "# Filter only CSV files\n",
    "csv_files = [file for file in files if file.endswith('.csv')]\n",
    "\n",
    "# Print the names of each CSV file\n",
    "print(\"CSV files in the directory:\")\n",
    "for csv_file in csv_files:\n",
    "    print(csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f568c76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: 1_1_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              1             7.0          2.0         1.0       6507.0   \n",
      "1              1             7.0          2.0         1.0       6508.0   \n",
      "2              1             7.0          2.0         1.0       6509.0   \n",
      "3              1             7.0          2.0         1.0       6514.0   \n",
      "4              1             7.0          2.0         1.0       6518.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  What advantage is there in booking directly wi...   \n",
      "1  Hi, Could someone please confirm if CX 884 - H...   \n",
      "2  I will be transiting Dubai soon en route to Oz...   \n",
      "3  Does anyone know where I'd find estimated pric...   \n",
      "4  It's from BA and finds the cheapest BA flight ...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  What advantage is there in booking directly wi...   \n",
      "1  [Hi, ]Could someone please confirm if CX 884 -...   \n",
      "2  [I will be transiting Dubai soon en route to O...   \n",
      "3  Does anyone know where I'd find estimated pric...   \n",
      "4  It's from BA and finds the cheapest BA flight ...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  What advantage is there in booking directly wi...   242.0  152.0   \n",
      "1  Hi, Could someone please confirm if CX 884 - H...   230.0  134.0   \n",
      "2  I will be transiting Dubai soon en route to Oz...   448.0  175.0   \n",
      "3  Does anyone know where I'd find estimated pric...   274.0   76.0   \n",
      "4  It's from BA and finds the cheapest BA flight ...    89.0    0.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         0.371901        0.0  \n",
      "1         0.417391        0.0  \n",
      "2         0.609375        1.0  \n",
      "3         0.722628        1.0  \n",
      "4         1.000000        1.0  \n",
      "\n",
      "Dataset: 1_2_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              1             7.0          2.0         2.0       7506.0   \n",
      "1              1             7.0          2.0         2.0       7507.0   \n",
      "2              1             7.0          2.0         2.0       7509.0   \n",
      "3              1             7.0          2.0         2.0       7510.0   \n",
      "4              1             7.0          2.0         2.0       7511.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  what is the price for round trip between toron...   \n",
      "1  trying to find a good deal and good timing to ...   \n",
      "2  trying to plan route penn ny to montgomery ny....   \n",
      "3  Hi does the 54 Vermonter train go from Newark,...   \n",
      "4  is there a train service from los angeles ca t...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  what is the price for round trip between toron...   \n",
      "1  trying to find a good deal and good timing to ...   \n",
      "2  trying to plan route penn ny to montgomery ny....   \n",
      "3  [Hi ]does the 54 Vermonter train go from Newar...   \n",
      "4  is there a train service from los angeles ca t...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  what is the price for round trip between toron...    61.0    0.0   \n",
      "1  [trying to find a ]good deal and good timing t...    81.0   17.0   \n",
      "2  trying to plan route penn ny to montgomery ny....    63.0   16.0   \n",
      "3  [Hi ]does the 54 Vermonter train go from Newar...    87.0   10.0   \n",
      "4  is there a train service from los angeles ca t...    64.0    0.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         1.000000        1.0  \n",
      "1         0.790123        0.0  \n",
      "2         0.746032        0.0  \n",
      "3         0.885057        1.0  \n",
      "4         1.000000        1.0  \n",
      "\n",
      "Dataset: 1_3_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              1             7.0          2.0         3.0       8506.0   \n",
      "1              1             7.0          2.0         3.0       8507.0   \n",
      "2              1             7.0          2.0         3.0       8508.0   \n",
      "3              1             7.0          2.0         3.0       8509.0   \n",
      "4              1             7.0          2.0         3.0       8510.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  If I reword my question, will you ask me to re...   \n",
      "1  ARE THERE ANY R-CLASS SEATS AVAILABLE ON ANY c...   \n",
      "2  I just changed my reservation and get miles re...   \n",
      "3  I purchased the ticket on the US Airways websi...   \n",
      "4  When we try to check in online we are told we ...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  If I reword my question, will you ask me to re...   \n",
      "1  ARE THERE ANY R-CLASS SEATS AVAILABLE ON ANY c...   \n",
      "2  I just changed my reservation and get miles re...   \n",
      "3  I purchased the ticket on the US Airways websi...   \n",
      "4  When we try to check in online we are told we ...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  [If I reword my question, ]will you ask me to ...    63.0   25.0   \n",
      "1  ARE THERE ANY R-CLASS SEATS AVAILABLE [ON ANY ...   115.0   20.0   \n",
      "2  [I just changed my reservation and get miles r...   111.0   53.0   \n",
      "3  [I purchased the ticket on the US Airways webs...   123.0   79.0   \n",
      "4  When we try to check in online we are told we ...    74.0   22.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         0.603175        0.0  \n",
      "1         0.826087        0.0  \n",
      "2         0.522523        1.0  \n",
      "3         0.357724        1.0  \n",
      "4         0.702703        0.0  \n",
      "\n",
      "Dataset: 1_4_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              1             7.0          2.0         4.0       9506.0   \n",
      "1              1             7.0          2.0         4.0       9507.0   \n",
      "2              1             7.0          2.0         4.0       9508.0   \n",
      "3              1             7.0          2.0         4.0       9509.0   \n",
      "4              1             7.0          2.0         4.0       9510.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  Ihave sent in my zipcode and put iit in my sig...   \n",
      "1  I moved my receiver to a different TV, the cha...   \n",
      "2  my hd isn't working on any of my televisions. ...   \n",
      "3  tv and cable will not turn on only get a blue ...   \n",
      "4  How do I get to the list of movies on Epix? I ...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  Ihave sent in my zipcode and put iit in my sig...   \n",
      "1  I moved my receiver to a different TV, the cha...   \n",
      "2  my hd isn't working on any of my televisions. ...   \n",
      "3  tv and cable will not turn on only get a blue ...   \n",
      "4  How do I get to the list of movies on Epix? [I...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  Ihave sent in my zipcode and [put iit in my si...   107.0   29.0   \n",
      "1  I moved my receiver to a different TV, the cha...   136.0    0.0   \n",
      "2  my hd isn't working on any of my televisions. ...   122.0   76.0   \n",
      "3  tv and cable will not turn on only get a blue ...    52.0    0.0   \n",
      "4  How do I get to the list of movies on Epix? [I...    59.0    0.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         0.728972        0.0  \n",
      "1         1.000000        1.0  \n",
      "2         0.377049        0.0  \n",
      "3         1.000000        1.0  \n",
      "4         1.000000        1.0  \n",
      "\n",
      "Dataset: 2_1_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              2             4.0          1.0         1.0       1464.0   \n",
      "1              2             4.0          1.0         1.0       1465.0   \n",
      "2              2             4.0          1.0         1.0       1466.0   \n",
      "3              2             4.0          1.0         1.0       1467.0   \n",
      "4              2             4.0          1.0         1.0       1468.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  Does NWA have a paid upgrade program like AS o...   \n",
      "1  i am having a problem finding web sites that h...   \n",
      "2  Would love to hear from you if you have any in...   \n",
      "3  I have an international departure tomorrow. An...   \n",
      "4  \"Visionaries are building everything from sexy...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  Does NWA have a paid upgrade program like AS o...   \n",
      "1  [i am having a problem finding web sites that ...   \n",
      "2  Would love to hear from you if you have any in...   \n",
      "3  I have an international departure tomorrow. An...   \n",
      "4  \"Visionaries are building everything from sexy...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  Does NWA have a paid upgrade program like AS o...   105.0    0.0   \n",
      "1  [i am having a problem finding web sites that ...   123.0   46.0   \n",
      "2  Would love to hear from you if you have any in...   275.0  104.0   \n",
      "3  [I have an international departure tomorrow.] ...   119.0   43.0   \n",
      "4  [\"Visionaries are building everything from sex...   271.0  271.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         1.000000        1.0  \n",
      "1         0.626016        1.0  \n",
      "2         0.621818        0.0  \n",
      "3         0.638655        0.0  \n",
      "4         0.000000        0.0  \n",
      "\n",
      "Dataset: 2_2_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              2             4.0          1.0         2.0       2752.0   \n",
      "1              2             4.0          1.0         2.0       2753.0   \n",
      "2              2             4.0          1.0         2.0       2754.0   \n",
      "3              2             4.0          1.0         2.0       2755.0   \n",
      "4              2             4.0          1.0         2.0       2756.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  how early do I need to be at the station befor...   \n",
      "1  Dear ----- I want to travel from San Diego to ...   \n",
      "2  what is one way fare from Joliet to Wisconsin ...   \n",
      "3  If I get on the train and purchase a ticket wi...   \n",
      "4  why is going from Philadelphia to New York Cit...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  how early do I need to be at the station befor...   \n",
      "1  [Dear ----- ]I want to travel from San Diego t...   \n",
      "2  what is one way fare from Joliet to Wisconsin ...   \n",
      "3  If I get on the train and purchase a ticket wi...   \n",
      "4  why is going from Philadelphia to New York Cit...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  how early do I need to be at the station befor...    66.0    0.0   \n",
      "1  Dear ----- I want to travel from San Diego to ...   200.0   11.0   \n",
      "2  what is one way fare from Joliet to Wisconsin ...    77.0    0.0   \n",
      "3  If I get on the train and purchase a ticket wi...    69.0    0.0   \n",
      "4  why is going from Philadelphia to New York Cit...    62.0    0.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0            1.000        1.0  \n",
      "1            0.945        1.0  \n",
      "2            1.000        1.0  \n",
      "3            1.000        1.0  \n",
      "4            1.000        1.0  \n",
      "\n",
      "Dataset: 2_3_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              2             4.0          1.0         3.0       4001.0   \n",
      "1              2             4.0          1.0         3.0       4002.0   \n",
      "2              2             4.0          1.0         3.0       4003.0   \n",
      "3              2             4.0          1.0         3.0       4004.0   \n",
      "4              2             4.0          1.0         3.0       4005.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  want to fly to GSP from SMF then to tampa and ...   \n",
      "1  I will be traveling in May and would like to u...   \n",
      "2  The email said I was changed to a flight 3 hou...   \n",
      "3  I flew in December and I attempted to move pre...   \n",
      "4  I paid for upgrade but doesn't show on my chec...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  want to fly to GSP from SMF then to tampa and ...   \n",
      "1  [I will be traveling in May and would like to ...   \n",
      "2  The email said I was changed to a flight 3 hou...   \n",
      "3  [I flew in December and ]I attempted to move p...   \n",
      "4  I paid for upgrade but doesn't show on my chec...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  want to fly to GSP from SMF then to tampa and ...   116.0    0.0   \n",
      "1  I will be traveling [in May ]and would like to...   200.0   72.0   \n",
      "2  [The email said ]I was changed to a flight 3 h...   144.0   77.0   \n",
      "3  [I flew in December and ]I attempted to move p...   196.0   32.0   \n",
      "4  I paid for upgrade but doesn't show on my chec...    63.0    0.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         1.000000        1.0  \n",
      "1         0.640000        1.0  \n",
      "2         0.465278        1.0  \n",
      "3         0.836735        1.0  \n",
      "4         1.000000        1.0  \n",
      "\n",
      "Dataset: 2_4_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              2             4.0          1.0         4.0       5251.0   \n",
      "1              2             4.0          1.0         4.0       5252.0   \n",
      "2              2             4.0          1.0         4.0       5253.0   \n",
      "3              2             4.0          1.0         4.0       5255.0   \n",
      "4              2             4.0          1.0         4.0       5256.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  I'm away from home and cannot verify my MAC ad...   \n",
      "1  I changed my user name why can't i move on the...   \n",
      "2  i paid my bill on 10/21 but it does not appear...   \n",
      "3  I am a subscriber to cname-- interntet and pho...   \n",
      "4  i GO TO PUT MY ZIPCODE INTO MY SIGN IN ARE AND...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  [I'm away from home and ]cannot verify my MAC ...   \n",
      "1  I changed my user name why can't i move on [th...   \n",
      "2  i paid my bill on 10/21 but it does not appear...   \n",
      "3  I am a subscriber to cname-- interntet and pho...   \n",
      "4  i GO TO PUT MY ZIPCODE INTO MY SIGN IN ARE AND...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  I'm away from home and cannot verify my MAC ad...    88.0   59.0   \n",
      "1  I changed my user name why can't i move on the...   122.0   58.0   \n",
      "2  i paid my bill on 10/21 but it does not appear...   182.0   53.0   \n",
      "3  I am a subscriber to cname-- interntet and pho...   167.0   74.0   \n",
      "4  i GO TO PUT MY ZIPCODE INTO MY SIGN IN [ARE] A...    84.0    3.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         0.329545        0.0  \n",
      "1         0.524590        1.0  \n",
      "2         0.708791        1.0  \n",
      "3         0.556886        0.0  \n",
      "4         0.964286        0.0  \n",
      "\n",
      "Dataset: 3_1_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              3             7.0          2.0         1.0       6507.0   \n",
      "1              3             7.0          2.0         1.0       6508.0   \n",
      "2              3             7.0          2.0         1.0       6509.0   \n",
      "3              3             7.0          2.0         1.0       6514.0   \n",
      "4              3             7.0          2.0         1.0       6518.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  What advantage is there in booking directly wi...   \n",
      "1  Hi, Could someone please confirm if CX 884 - H...   \n",
      "2  I will be transiting Dubai soon en route to Oz...   \n",
      "3  Does anyone know where I'd find estimated pric...   \n",
      "4  It's from BA and finds the cheapest BA flight ...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  What advantage is there in booking directly wi...   \n",
      "1  Hi, Could someone please confirm if CX 884 - H...   \n",
      "2  [I will be transiting Dubai soon en route to O...   \n",
      "3  Does anyone know where I'd find estimated pric...   \n",
      "4  It's from BA and finds the cheapest BA flight ...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  What advantage is there in booking directly wi...   242.0  152.0   \n",
      "1  Hi, Could someone please confirm if CX 884 - H...   230.0  130.0   \n",
      "2  I will be transiting Dubai soon en route to Oz...   448.0  175.0   \n",
      "3  Does anyone know where I'd find estimated pric...   274.0  134.0   \n",
      "4  It's from BA and finds the cheapest BA flight ...    89.0    0.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         0.371901        0.0  \n",
      "1         0.434783        0.0  \n",
      "2         0.609375        1.0  \n",
      "3         0.510949        1.0  \n",
      "4         1.000000        1.0  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: 3_2_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              3             7.0          2.0         2.0       7506.0   \n",
      "1              3             7.0          2.0         2.0       7507.0   \n",
      "2              3             7.0          2.0         2.0       7509.0   \n",
      "3              3             7.0          2.0         2.0       7510.0   \n",
      "4              3             7.0          2.0         2.0       7511.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  what is the price for round trip between toron...   \n",
      "1  trying to find a good deal and good timing to ...   \n",
      "2  trying to plan route penn ny to montgomery ny....   \n",
      "3  Hi does the 54 Vermonter train go from Newark,...   \n",
      "4  is there a train service from los angeles ca t...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  what is the price for round trip between toron...   \n",
      "1  trying to find a good deal [and good timing ]t...   \n",
      "2  trying to plan route penn ny to montgomery ny....   \n",
      "3  Hi does the 54 Vermonter train go from Newark,...   \n",
      "4  is there a train service from los angeles ca t...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  what is the price for round trip between toron...    61.0    0.0   \n",
      "1  [trying to find a ]good deal and good timing t...    81.0   33.0   \n",
      "2  trying to plan route penn ny to montgomery ny....    63.0    0.0   \n",
      "3  [Hi ]does the 54 Vermonter train go from Newar...    87.0   13.0   \n",
      "4  is there a train service from los angeles ca t...    64.0    0.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         1.000000        1.0  \n",
      "1         0.592593        1.0  \n",
      "2         1.000000        1.0  \n",
      "3         0.850575        0.0  \n",
      "4         1.000000        1.0  \n",
      "\n",
      "Dataset: 3_3_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              3             7.0          2.0         3.0       8506.0   \n",
      "1              3             7.0          2.0         3.0       8507.0   \n",
      "2              3             7.0          2.0         3.0       8508.0   \n",
      "3              3             7.0          2.0         3.0       8509.0   \n",
      "4              3             7.0          2.0         3.0       8510.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  If I reword my question, will you ask me to re...   \n",
      "1  ARE THERE ANY R-CLASS SEATS AVAILABLE ON ANY c...   \n",
      "2  I just changed my reservation and get miles re...   \n",
      "3  I purchased the ticket on the US Airways websi...   \n",
      "4  When we try to check in online we are told we ...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  [If I reword my question, ]will you ask me to ...   \n",
      "1  ARE THERE ANY R-CLASS SEATS AVAILABLE ON ANY c...   \n",
      "2  [I just changed my reservation and get miles r...   \n",
      "3  I purchased the ticket on the US Airways websi...   \n",
      "4  When we try to check in online we are told we ...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  [If I reword my question, ]will you ask me to ...    63.0    0.0   \n",
      "1  ARE THERE ANY R-CLASS SEATS AVAILABLE [ON ANY ...   115.0   20.0   \n",
      "2  [I just changed my reservation and get miles r...   111.0    7.0   \n",
      "3  [I purchased the ticket on the US Airways webs...   123.0   79.0   \n",
      "4  When we try to check in online we are told we ...    74.0   22.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         1.000000        1.0  \n",
      "1         0.826087        0.0  \n",
      "2         0.936937        1.0  \n",
      "3         0.357724        1.0  \n",
      "4         0.702703        0.0  \n",
      "\n",
      "Dataset: 3_4_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              3             7.0          2.0         4.0       9506.0   \n",
      "1              3             7.0          2.0         4.0       9507.0   \n",
      "2              3             7.0          2.0         4.0       9508.0   \n",
      "3              3             7.0          2.0         4.0       9509.0   \n",
      "4              3             7.0          2.0         4.0       9510.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  Ihave sent in my zipcode and put iit in my sig...   \n",
      "1  I moved my receiver to a different TV, the cha...   \n",
      "2  my hd isn't working on any of my televisions. ...   \n",
      "3  tv and cable will not turn on only get a blue ...   \n",
      "4  How do I get to the list of movies on Epix? I ...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  [Ihave sent in my zipcode and put iit in my si...   \n",
      "1  I moved my receiver to a different TV, the cha...   \n",
      "2  my hd isn't working on any of my televisions. ...   \n",
      "3  tv and cable will not turn on only get a blue ...   \n",
      "4  How do I get to the list of movies on Epix? [I...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  Ihave sent in my zipcode and [put iit in my si...   107.0   76.0   \n",
      "1  I moved my receiver to a different TV, the cha...   136.0    0.0   \n",
      "2  my hd isn't working on any of my televisions. ...   122.0   76.0   \n",
      "3  tv and cable will not turn on only get a blue ...    52.0    0.0   \n",
      "4  How do I get to the list of movies on Epix? [I...    59.0    0.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         0.289720        1.0  \n",
      "1         1.000000        1.0  \n",
      "2         0.377049        0.0  \n",
      "3         1.000000        1.0  \n",
      "4         1.000000        1.0  \n",
      "\n",
      "Dataset: 4_1_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              4             8.0          1.0         1.0       1464.0   \n",
      "1              4             8.0          1.0         1.0       1465.0   \n",
      "2              4             8.0          1.0         1.0       1466.0   \n",
      "3              4             8.0          1.0         1.0       1467.0   \n",
      "4              4             8.0          1.0         1.0       1468.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  Does NWA have a paid upgrade program like AS o...   \n",
      "1  i am having a problem finding web sites that h...   \n",
      "2  Would love to hear from you if you have any in...   \n",
      "3  I have an international departure tomorrow. An...   \n",
      "4  \"Visionaries are building everything from sexy...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  Does NWA have a paid upgrade program like AS o...   \n",
      "1  [i am having a problem finding web sites that ...   \n",
      "2  Would love to hear from you if you have any in...   \n",
      "3  [I have an international departure tomorrow.] ...   \n",
      "4  [\"Visionaries are building everything from sex...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  Does NWA have a paid upgrade program like AS o...   105.0    0.0   \n",
      "1  [i am having a ]problem finding web sites that...   123.0  101.0   \n",
      "2  [Would love to hear from you if you have any i...   275.0  101.0   \n",
      "3  I have an international departure tomorrow.[ A...   119.0   58.0   \n",
      "4  [\"Visionaries are building everything from sex...   271.0    0.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         1.000000        1.0  \n",
      "1         0.178862        1.0  \n",
      "2         0.632727        0.0  \n",
      "3         0.512605        1.0  \n",
      "4         1.000000        1.0  \n",
      "\n",
      "Dataset: 4_2_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              4             8.0          1.0         2.0       2752.0   \n",
      "1              4             8.0          1.0         2.0       2753.0   \n",
      "2              4             8.0          1.0         2.0       2754.0   \n",
      "3              4             8.0          1.0         2.0       2755.0   \n",
      "4              4             8.0          1.0         2.0       2756.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  how early do I need to be at the station befor...   \n",
      "1  Dear ----- I want to travel from San Diego to ...   \n",
      "2  what is one way fare from Joliet to Wisconsin ...   \n",
      "3  If I get on the train and purchase a ticket wi...   \n",
      "4  why is going from Philadelphia to New York Cit...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  how early do I need to be at the station befor...   \n",
      "1  Dear ----- I want to travel from San Diego to ...   \n",
      "2  what is one way fare from Joliet to Wisconsin ...   \n",
      "3  If I get on the train and purchase a ticket wi...   \n",
      "4  why is going from Philadelphia to New York Cit...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  how early do I need to be at the station befor...    66.0    0.0   \n",
      "1  [Dear ----- ]I want to travel from San Diego t...   200.0   11.0   \n",
      "2  what is one way fare from Joliet to Wisconsin ...    77.0    0.0   \n",
      "3  If I get on the train and purchase a ticket wi...    69.0    0.0   \n",
      "4  why is going from Philadelphia to New York Cit...    62.0    0.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0            1.000        1.0  \n",
      "1            0.945        1.0  \n",
      "2            1.000        1.0  \n",
      "3            1.000        1.0  \n",
      "4            1.000        1.0  \n",
      "\n",
      "Dataset: 4_3_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              4             8.0          1.0         3.0       4001.0   \n",
      "1              4             8.0          1.0         3.0       4002.0   \n",
      "2              4             8.0          1.0         3.0       4003.0   \n",
      "3              4             8.0          1.0         3.0       4004.0   \n",
      "4              4             8.0          1.0         3.0       4005.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  want to fly to GSP from SMF then to tampa and ...   \n",
      "1  I will be traveling in May and would like to u...   \n",
      "2  The email said I was changed to a flight 3 hou...   \n",
      "3  I flew in December and I attempted to move pre...   \n",
      "4  I paid for upgrade but doesn't show on my chec...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  want to fly to GSP from SMF then to tampa and ...   \n",
      "1  I will be traveling [in May ]and would like to...   \n",
      "2  [The email said ]I was changed to a flight 3 h...   \n",
      "3  [I flew in December and ]I attempted to move p...   \n",
      "4  I paid for upgrade but doesn't show on my chec...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  want to fly to GSP from SMF then to tampa and ...   116.0    0.0   \n",
      "1  I will be traveling in May and would like to u...   200.0   17.0   \n",
      "2  The email said I was changed to a flight 3 hou...   144.0   15.0   \n",
      "3  I flew in December and I attempted to move pre...   196.0   36.0   \n",
      "4  I paid for upgrade but doesn't show on my chec...    63.0    0.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         1.000000        1.0  \n",
      "1         0.915000        1.0  \n",
      "2         0.895833        0.0  \n",
      "3         0.816327        0.0  \n",
      "4         1.000000        1.0  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: 4_4_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              4             8.0          1.0         4.0       5251.0   \n",
      "1              4             8.0          1.0         4.0       5252.0   \n",
      "2              4             8.0          1.0         4.0       5253.0   \n",
      "3              4             8.0          1.0         4.0       5255.0   \n",
      "4              4             8.0          1.0         4.0       5256.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  I'm away from home and cannot verify my MAC ad...   \n",
      "1  I changed my user name why can't i move on the...   \n",
      "2  i paid my bill on 10/21 but it does not appear...   \n",
      "3  I am a subscriber to cname-- interntet and pho...   \n",
      "4  i GO TO PUT MY ZIPCODE INTO MY SIGN IN ARE AND...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  I'm away from home and cannot verify my MAC ad...   \n",
      "1  I changed my user name why can't i move on the...   \n",
      "2  i paid my bill on 10/21 but it does not appear...   \n",
      "3  I am a subscriber to cname-- interntet and pho...   \n",
      "4  i GO TO PUT MY ZIPCODE INTO MY SIGN IN [ARE] A...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  I'm away from home and cannot verify my MAC ad...    88.0    0.0   \n",
      "1  I changed my user name why can't i move on the...   122.0   20.0   \n",
      "2  i paid my bill on 10/21 but it does not appear...   182.0   30.0   \n",
      "3  [I am a subscriber to cname-- interntet and ph...   167.0   92.0   \n",
      "4  i GO TO PUT MY ZIPCODE INTO MY SIGN IN ARE AND...    84.0    3.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         1.000000        1.0  \n",
      "1         0.836066        0.0  \n",
      "2         0.835165        0.0  \n",
      "3         0.449102        0.0  \n",
      "4         0.964286        0.0  \n",
      "\n",
      "Dataset: 5_1_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              5             7.0          2.0         1.0       6507.0   \n",
      "1              5             7.0          2.0         1.0       6508.0   \n",
      "2              5             7.0          2.0         1.0       6509.0   \n",
      "3              5             7.0          2.0         1.0       6514.0   \n",
      "4              5             7.0          2.0         1.0       6518.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  What advantage is there in booking directly wi...   \n",
      "1  Hi, Could someone please confirm if CX 884 - H...   \n",
      "2  I will be transiting Dubai soon en route to Oz...   \n",
      "3  Does anyone know where I'd find estimated pric...   \n",
      "4  It's from BA and finds the cheapest BA flight ...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  What advantage is there in booking directly wi...   \n",
      "1  Hi, Could someone please confirm if CX 884 - H...   \n",
      "2  [I will be transiting Dubai soon en route to O...   \n",
      "3  [Does anyone know where I'd find ]estimated pr...   \n",
      "4  It's from BA and finds the cheapest BA flight ...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  What advantage is there in booking directly wi...   242.0  152.0   \n",
      "1  Hi, Could someone please confirm if CX 884 - H...   230.0  130.0   \n",
      "2  I will be transiting Dubai soon en route to Oz...   448.0  162.0   \n",
      "3  Does anyone know where I'd find estimated pric...   274.0  157.0   \n",
      "4  It's from BA and finds the cheapest BA flight ...    89.0    0.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         0.371901        0.0  \n",
      "1         0.434783        0.0  \n",
      "2         0.638393        1.0  \n",
      "3         0.427007        1.0  \n",
      "4         1.000000        1.0  \n",
      "\n",
      "Dataset: 5_2_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              5             7.0          2.0         2.0       7506.0   \n",
      "1              5             7.0          2.0         2.0       7507.0   \n",
      "2              5             7.0          2.0         2.0       7509.0   \n",
      "3              5             7.0          2.0         2.0       7510.0   \n",
      "4              5             7.0          2.0         2.0       7511.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  what is the price for round trip between toron...   \n",
      "1  trying to find a good deal and good timing to ...   \n",
      "2  trying to plan route penn ny to montgomery ny....   \n",
      "3  Hi does the 54 Vermonter train go from Newark,...   \n",
      "4  is there a train service from los angeles ca t...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  what is the price for round trip between toron...   \n",
      "1  trying to find a good deal [and good timing] t...   \n",
      "2  trying to plan route penn ny to montgomery ny....   \n",
      "3  [Hi ]does the 54 Vermonter train go from Newar...   \n",
      "4  is there a train service from los angeles ca t...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  what is the price for round trip between toron...    61.0    0.0   \n",
      "1  [trying to find a ]good deal and good timing t...    81.0   32.0   \n",
      "2  trying to plan route penn ny to montgomery ny....    63.0   16.0   \n",
      "3  [Hi ]does the 54 Vermonter train go from Newar...    87.0   10.0   \n",
      "4  is there a train service from los angeles ca t...    64.0    0.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         1.000000        1.0  \n",
      "1         0.604938        1.0  \n",
      "2         0.746032        0.0  \n",
      "3         0.885057        1.0  \n",
      "4         1.000000        1.0  \n",
      "\n",
      "Dataset: 5_3_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              5             7.0          2.0         3.0       8506.0   \n",
      "1              5             7.0          2.0         3.0       8507.0   \n",
      "2              5             7.0          2.0         3.0       8508.0   \n",
      "3              5             7.0          2.0         3.0       8509.0   \n",
      "4              5             7.0          2.0         3.0       8510.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  If I reword my question, will you ask me to re...   \n",
      "1  ARE THERE ANY R-CLASS SEATS AVAILABLE ON ANY c...   \n",
      "2  I just changed my reservation and get miles re...   \n",
      "3  I purchased the ticket on the US Airways websi...   \n",
      "4  When we try to check in online we are told we ...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  If I reword my question, will you ask me to re...   \n",
      "1  ARE THERE ANY R-CLASS SEATS AVAILABLE ON ANY c...   \n",
      "2  I just changed my reservation and get miles re...   \n",
      "3  I purchased the ticket on the US Airways websi...   \n",
      "4  When we try to check in online we are told we ...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  [If I reword my question, ]will you ask me to ...    63.0   25.0   \n",
      "1  ARE THERE ANY R-CLASS SEATS AVAILABLE [ON ANY ...   115.0   20.0   \n",
      "2  [I just changed my reservation and get miles r...   111.0   53.0   \n",
      "3  [I purchased the ticket on the US Airways webs...   123.0   79.0   \n",
      "4  When we try to check in online we are told we ...    74.0    0.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         0.603175        0.0  \n",
      "1         0.826087        0.0  \n",
      "2         0.522523        1.0  \n",
      "3         0.357724        1.0  \n",
      "4         1.000000        1.0  \n",
      "\n",
      "Dataset: 5_4_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              5             7.0          2.0         4.0       9506.0   \n",
      "1              5             7.0          2.0         4.0       9507.0   \n",
      "2              5             7.0          2.0         4.0       9508.0   \n",
      "3              5             7.0          2.0         4.0       9509.0   \n",
      "4              5             7.0          2.0         4.0       9510.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  Ihave sent in my zipcode and put iit in my sig...   \n",
      "1  I moved my receiver to a different TV, the cha...   \n",
      "2  my hd isn't working on any of my televisions. ...   \n",
      "3  tv and cable will not turn on only get a blue ...   \n",
      "4  How do I get to the list of movies on Epix? I ...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  [Ihave sent in my zipcode and put iit in my si...   \n",
      "1  [I moved my receiver to a different TV, ]the c...   \n",
      "2  my hd isn't working on any of my televisions. ...   \n",
      "3  tv and cable will not turn on only get a blue ...   \n",
      "4  How do I get to the list of movies on Epix? I ...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  Ihave sent in my zipcode and [put iit in my si...   107.0   28.0   \n",
      "1  I moved my receiver to a different TV, the cha...   136.0   39.0   \n",
      "2  my hd isn't working on any of my televisions. ...   122.0   76.0   \n",
      "3  tv and cable will not turn on only get a blue ...    52.0    0.0   \n",
      "4  How do I get to the list of movies on Epix? [I...    59.0   14.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         0.738318        1.0  \n",
      "1         0.713235        0.0  \n",
      "2         0.377049        0.0  \n",
      "3         1.000000        1.0  \n",
      "4         0.762712        0.0  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: 6_1_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              6             4.0          1.0         1.0       1464.0   \n",
      "1              6             4.0          1.0         1.0       1465.0   \n",
      "2              6             4.0          1.0         1.0       1466.0   \n",
      "3              6             4.0          1.0         1.0       1467.0   \n",
      "4              6             4.0          1.0         1.0       1468.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  Does NWA have a paid upgrade program like AS o...   \n",
      "1  i am having a problem finding web sites that h...   \n",
      "2  Would love to hear from you if you have any in...   \n",
      "3  I have an international departure tomorrow. An...   \n",
      "4  \"Visionaries are building everything from sexy...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  Does NWA have a paid upgrade program like AS o...   \n",
      "1  [i am having a problem finding web sites that ...   \n",
      "2  Would love to hear from you if you have any in...   \n",
      "3  [I have an international departure tomorrow. ]...   \n",
      "4  \"Visionaries are building everything from sexy...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  Does NWA have a paid upgrade program like AS o...   105.0    0.0   \n",
      "1  [i am having a problem finding web sites that ...   123.0   46.0   \n",
      "2  Would love to hear from you if you have any in...   275.0  105.0   \n",
      "3  [I have an international departure tomorrow.] ...   119.0    0.0   \n",
      "4  [\"Visionaries are building everything from sex...   271.0  271.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         1.000000        1.0  \n",
      "1         0.626016        1.0  \n",
      "2         0.618182        0.0  \n",
      "3         1.000000        1.0  \n",
      "4         0.000000        0.0  \n",
      "\n",
      "Dataset: 6_2_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              6             4.0          1.0         2.0       2752.0   \n",
      "1              6             4.0          1.0         2.0       2753.0   \n",
      "2              6             4.0          1.0         2.0       2754.0   \n",
      "3              6             4.0          1.0         2.0       2755.0   \n",
      "4              6             4.0          1.0         2.0       2756.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  how early do I need to be at the station befor...   \n",
      "1  Dear ----- I want to travel from San Diego to ...   \n",
      "2  what is one way fare from Joliet to Wisconsin ...   \n",
      "3  If I get on the train and purchase a ticket wi...   \n",
      "4  why is going from Philadelphia to New York Cit...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  how early do I need to be at the station befor...   \n",
      "1  Dear ----- I want to travel from San Diego to ...   \n",
      "2  what is one way fare from Joliet to Wisconsin ...   \n",
      "3  If I get on the train and purchase a ticket wi...   \n",
      "4  why is going from Philadelphia to New York Cit...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  how early do I need to be at the station befor...    66.0    0.0   \n",
      "1  Dear ----- I want to travel from San Diego to ...   200.0   61.0   \n",
      "2  what is one way fare from Joliet to Wisconsin ...    77.0    0.0   \n",
      "3  If I get on the train and purchase a ticket wi...    69.0    0.0   \n",
      "4  why is going from Philadelphia to New York Cit...    62.0    0.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0            1.000        1.0  \n",
      "1            0.695        1.0  \n",
      "2            1.000        1.0  \n",
      "3            1.000        1.0  \n",
      "4            1.000        1.0  \n",
      "\n",
      "Dataset: 6_3_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              6             4.0          1.0         3.0       4001.0   \n",
      "1              6             4.0          1.0         3.0       4002.0   \n",
      "2              6             4.0          1.0         3.0       4003.0   \n",
      "3              6             4.0          1.0         3.0       4004.0   \n",
      "4              6             4.0          1.0         3.0       4005.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  want to fly to GSP from SMF then to tampa and ...   \n",
      "1  I will be traveling in May and would like to u...   \n",
      "2  The email said I was changed to a flight 3 hou...   \n",
      "3  I flew in December and I attempted to move pre...   \n",
      "4  I paid for upgrade but doesn't show on my chec...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  [want to fly to GSP from SMF then to tampa and...   \n",
      "1  I will be traveling in May and would like to u...   \n",
      "2  The email said I was changed to a flight 3 hou...   \n",
      "3  [I flew in December and I attempted to ]move p...   \n",
      "4  I paid for upgrade but doesn't show on my chec...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  want to fly to GSP from SMF then to tampa and ...   116.0   64.0   \n",
      "1  I will be traveling [in May ]and would like to...   200.0   68.0   \n",
      "2  [The email said ]I was changed to a flight 3 h...   144.0  102.0   \n",
      "3  [I flew in December and ]I attempted to move p...   196.0  108.0   \n",
      "4  I paid for upgrade but doesn't show on my chec...    63.0    0.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         0.448276        0.0  \n",
      "1         0.660000        1.0  \n",
      "2         0.291667        1.0  \n",
      "3         0.448980        1.0  \n",
      "4         1.000000        1.0  \n",
      "\n",
      "Dataset: 6_4_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              6             4.0          1.0         4.0       5251.0   \n",
      "1              6             4.0          1.0         4.0       5252.0   \n",
      "2              6             4.0          1.0         4.0       5253.0   \n",
      "3              6             4.0          1.0         4.0       5255.0   \n",
      "4              6             4.0          1.0         4.0       5256.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  I'm away from home and cannot verify my MAC ad...   \n",
      "1  I changed my user name why can't i move on the...   \n",
      "2  i paid my bill on 10/21 but it does not appear...   \n",
      "3  I am a subscriber to cname-- interntet and pho...   \n",
      "4  i GO TO PUT MY ZIPCODE INTO MY SIGN IN ARE AND...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  I'm away from home and cannot verify my MAC ad...   \n",
      "1  I changed my user name why can't i move on [th...   \n",
      "2  i paid my bill on 10/21 but it does not appear...   \n",
      "3  [I am a subscriber to cname-- interntet and ph...   \n",
      "4  i GO TO PUT MY ZIPCODE INTO MY SIGN IN ARE AND...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  I'm away from home and cannot verify my MAC ad...    88.0   36.0   \n",
      "1  I changed my user name why can't i move on the...   122.0   58.0   \n",
      "2  i paid my bill on 10/21 but it does not appear...   182.0   53.0   \n",
      "3  I am a subscriber to cname-- interntet and pho...   167.0  128.0   \n",
      "4  i GO TO PUT MY ZIPCODE INTO MY SIGN IN [ARE] A...    84.0    3.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         0.590909        0.0  \n",
      "1         0.524590        1.0  \n",
      "2         0.708791        1.0  \n",
      "3         0.233533        0.0  \n",
      "4         0.964286        0.0  \n",
      "\n",
      "Dataset: 7_1_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              7             3.0          2.0         1.0       6507.0   \n",
      "1              7             3.0          2.0         1.0       6508.0   \n",
      "2              7             3.0          2.0         1.0       6509.0   \n",
      "3              7             3.0          2.0         1.0       6514.0   \n",
      "4              7             3.0          2.0         1.0       6518.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  What advantage is there in booking directly wi...   \n",
      "1  Hi, Could someone please confirm if CX 884 - H...   \n",
      "2  I will be transiting Dubai soon en route to Oz...   \n",
      "3  Does anyone know where I'd find estimated pric...   \n",
      "4  It's from BA and finds the cheapest BA flight ...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  What advantage is there in booking directly wi...   \n",
      "1  Hi, Could someone please confirm if CX 884 - H...   \n",
      "2  I will be transiting Dubai soon en route to Oz...   \n",
      "3  Does anyone know where I'd find estimated pric...   \n",
      "4  It's from BA and finds the cheapest BA flight ...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  What advantage is there in booking directly wi...   242.0  152.0   \n",
      "1  Hi, Could someone please confirm if CX 884 - H...   230.0  130.0   \n",
      "2  [I will be transiting Dubai soon en route to O...   448.0  175.0   \n",
      "3  Does anyone know where I'd find estimated pric...   274.0  134.0   \n",
      "4  It's from BA and finds the cheapest BA flight ...    89.0    0.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         0.371901        0.0  \n",
      "1         0.434783        0.0  \n",
      "2         0.609375        1.0  \n",
      "3         0.510949        1.0  \n",
      "4         1.000000        1.0  \n",
      "\n",
      "Dataset: 7_2_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              7             3.0          2.0         2.0       7506.0   \n",
      "1              7             3.0          2.0         2.0       7507.0   \n",
      "2              7             3.0          2.0         2.0       7509.0   \n",
      "3              7             3.0          2.0         2.0       7510.0   \n",
      "4              7             3.0          2.0         2.0       7511.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  what is the price for round trip between toron...   \n",
      "1  trying to find a good deal and good timing to ...   \n",
      "2  trying to plan route penn ny to montgomery ny....   \n",
      "3  Hi does the 54 Vermonter train go from Newark,...   \n",
      "4  is there a train service from los angeles ca t...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  what is the price for round trip between toron...   \n",
      "1  [trying to find a ]good deal and good timing t...   \n",
      "2  trying to plan route penn ny to montgomery ny....   \n",
      "3  [Hi ]does the 54 Vermonter train go from Newar...   \n",
      "4  is there a train service from los angeles ca t...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  what is the price for round trip between toron...    61.0    0.0   \n",
      "1  trying to find a good deal [and good timing ]t...    81.0   33.0   \n",
      "2  trying to plan route penn ny to montgomery ny....    63.0    0.0   \n",
      "3  Hi does the 54 Vermonter train go from Newark,...    87.0   13.0   \n",
      "4  is there a train service from los angeles ca t...    64.0    0.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         1.000000        1.0  \n",
      "1         0.592593        1.0  \n",
      "2         1.000000        1.0  \n",
      "3         0.850575        0.0  \n",
      "4         1.000000        1.0  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: 7_3_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              7             3.0          2.0         3.0       8506.0   \n",
      "1              7             3.0          2.0         3.0       8507.0   \n",
      "2              7             3.0          2.0         3.0       8508.0   \n",
      "3              7             3.0          2.0         3.0       8509.0   \n",
      "4              7             3.0          2.0         3.0       8510.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  If I reword my question, will you ask me to re...   \n",
      "1  ARE THERE ANY R-CLASS SEATS AVAILABLE ON ANY c...   \n",
      "2  I just changed my reservation and get miles re...   \n",
      "3  I purchased the ticket on the US Airways websi...   \n",
      "4  When we try to check in online we are told we ...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  [If I reword my question, ]will you ask me to ...   \n",
      "1  ARE THERE ANY R-CLASS SEATS AVAILABLE [ON ANY ...   \n",
      "2  [I just changed my reservation and get miles r...   \n",
      "3  [I purchased the ticket on the US Airways webs...   \n",
      "4  When we try to check in online we are told we ...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  [If I reword my question, ]will you ask me to ...    63.0    0.0   \n",
      "1  ARE THERE ANY R-CLASS SEATS AVAILABLE ON ANY c...   115.0   20.0   \n",
      "2  [I just changed my reservation and get miles r...   111.0    7.0   \n",
      "3  I purchased the ticket on the US Airways websi...   123.0   79.0   \n",
      "4  When we try to check in online we are told we ...    74.0   22.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         1.000000        1.0  \n",
      "1         0.826087        0.0  \n",
      "2         0.936937        1.0  \n",
      "3         0.357724        1.0  \n",
      "4         0.702703        0.0  \n",
      "\n",
      "Dataset: 7_4_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              7             3.0          2.0         4.0       9506.0   \n",
      "1              7             3.0          2.0         4.0       9507.0   \n",
      "2              7             3.0          2.0         4.0       9508.0   \n",
      "3              7             3.0          2.0         4.0       9509.0   \n",
      "4              7             3.0          2.0         4.0       9510.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  Ihave sent in my zipcode and put iit in my sig...   \n",
      "1  I moved my receiver to a different TV, the cha...   \n",
      "2  my hd isn't working on any of my televisions. ...   \n",
      "3  tv and cable will not turn on only get a blue ...   \n",
      "4  How do I get to the list of movies on Epix? I ...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  Ihave sent in my zipcode and [put iit in my si...   \n",
      "1  I moved my receiver to a different TV, the cha...   \n",
      "2  my hd isn't working on any of my televisions. ...   \n",
      "3  tv and cable will not turn on only get a blue ...   \n",
      "4  How do I get to the list of movies on Epix? [I...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  [Ihave sent in my zipcode and put iit in my si...   107.0   76.0   \n",
      "1  I moved my receiver to a different TV, the cha...   136.0    0.0   \n",
      "2  my hd isn't working on any of my televisions. ...   122.0   76.0   \n",
      "3  tv and cable will not turn on only get a blue ...    52.0    0.0   \n",
      "4  How do I get to the list of movies on Epix? [I...    59.0    0.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         0.289720        1.0  \n",
      "1         1.000000        1.0  \n",
      "2         0.377049        0.0  \n",
      "3         1.000000        1.0  \n",
      "4         1.000000        1.0  \n",
      "\n",
      "Dataset: 8_1_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              8             4.0          1.0         1.0       1464.0   \n",
      "1              8             4.0          1.0         1.0       1465.0   \n",
      "2              8             4.0          1.0         1.0       1466.0   \n",
      "3              8             4.0          1.0         1.0       1467.0   \n",
      "4              8             4.0          1.0         1.0       1468.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  Does NWA have a paid upgrade program like AS o...   \n",
      "1  i am having a problem finding web sites that h...   \n",
      "2  Would love to hear from you if you have any in...   \n",
      "3  I have an international departure tomorrow. An...   \n",
      "4  \"Visionaries are building everything from sexy...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  Does NWA have a paid upgrade program like AS o...   \n",
      "1  [i am having a ]problem finding web sites that...   \n",
      "2  [Would love to hear from you if you have any i...   \n",
      "3  I have an international departure tomorrow.[ A...   \n",
      "4  [\"Visionaries are building everything from sex...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  Does NWA have a paid upgrade program like AS o...   105.0    0.0   \n",
      "1  [i am having a problem finding web sites that ...   123.0  101.0   \n",
      "2  Would love to hear from you if you have any in...   275.0  101.0   \n",
      "3  [I have an international departure tomorrow.] ...   119.0   58.0   \n",
      "4  [\"Visionaries are building everything from sex...   271.0    0.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         1.000000        1.0  \n",
      "1         0.178862        1.0  \n",
      "2         0.632727        0.0  \n",
      "3         0.512605        1.0  \n",
      "4         1.000000        1.0  \n",
      "\n",
      "Dataset: 8_2_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              8             4.0          1.0         2.0       2752.0   \n",
      "1              8             4.0          1.0         2.0       2753.0   \n",
      "2              8             4.0          1.0         2.0       2754.0   \n",
      "3              8             4.0          1.0         2.0       2755.0   \n",
      "4              8             4.0          1.0         2.0       2756.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  how early do I need to be at the station befor...   \n",
      "1  Dear ----- I want to travel from San Diego to ...   \n",
      "2  what is one way fare from Joliet to Wisconsin ...   \n",
      "3  If I get on the train and purchase a ticket wi...   \n",
      "4  why is going from Philadelphia to New York Cit...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  how early do I need to be at the station befor...   \n",
      "1  [Dear ----- ]I want to travel from San Diego t...   \n",
      "2  what is one way fare from Joliet to Wisconsin ...   \n",
      "3  If I get on the train and purchase a ticket wi...   \n",
      "4  why is going from Philadelphia to New York Cit...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  how early do I need to be at the station befor...    66.0    0.0   \n",
      "1  Dear ----- I want to travel from San Diego to ...   200.0   11.0   \n",
      "2  what is one way fare from Joliet to Wisconsin ...    77.0    0.0   \n",
      "3  If I get on the train and purchase a ticket wi...    69.0    0.0   \n",
      "4  why is going from Philadelphia to New York Cit...    62.0    0.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0            1.000        1.0  \n",
      "1            0.945        1.0  \n",
      "2            1.000        1.0  \n",
      "3            1.000        1.0  \n",
      "4            1.000        1.0  \n",
      "\n",
      "Dataset: 8_3_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              8             4.0          1.0         3.0       4001.0   \n",
      "1              8             4.0          1.0         3.0       4002.0   \n",
      "2              8             4.0          1.0         3.0       4003.0   \n",
      "3              8             4.0          1.0         3.0       4004.0   \n",
      "4              8             4.0          1.0         3.0       4005.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  want to fly to GSP from SMF then to tampa and ...   \n",
      "1  I will be traveling in May and would like to u...   \n",
      "2  The email said I was changed to a flight 3 hou...   \n",
      "3  I flew in December and I attempted to move pre...   \n",
      "4  I paid for upgrade but doesn't show on my chec...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  want to fly to GSP from SMF then to tampa and ...   \n",
      "1  I will be traveling in May and would like to u...   \n",
      "2  The email said I was changed to a flight 3 hou...   \n",
      "3  I flew in December and I attempted to move pre...   \n",
      "4  I paid for upgrade but doesn't show on my chec...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  want to fly to GSP from SMF then to tampa and ...   116.0    0.0   \n",
      "1  I will be traveling [in May ]and would like to...   200.0   17.0   \n",
      "2  [The email said ]I was changed to a flight 3 h...   144.0   15.0   \n",
      "3  [I flew in December and ]I attempted to move p...   196.0   36.0   \n",
      "4  I paid for upgrade but doesn't show on my chec...    63.0    0.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         1.000000        1.0  \n",
      "1         0.915000        1.0  \n",
      "2         0.895833        0.0  \n",
      "3         0.816327        0.0  \n",
      "4         1.000000        1.0  \n",
      "\n",
      "Dataset: 8_4_align.csv\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              8             4.0          1.0         4.0       5251.0   \n",
      "1              8             4.0          1.0         4.0       5252.0   \n",
      "2              8             4.0          1.0         4.0       5253.0   \n",
      "3              8             4.0          1.0         4.0       5255.0   \n",
      "4              8             4.0          1.0         4.0       5256.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  I'm away from home and cannot verify my MAC ad...   \n",
      "1  I changed my user name why can't i move on the...   \n",
      "2  i paid my bill on 10/21 but it does not appear...   \n",
      "3  I am a subscriber to cname-- interntet and pho...   \n",
      "4  i GO TO PUT MY ZIPCODE INTO MY SIGN IN ARE AND...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  I'm away from home and cannot verify my MAC ad...   \n",
      "1  I changed my user name why can't i move on the...   \n",
      "2  i paid my bill on 10/21 but it does not appear...   \n",
      "3  [I am a subscriber to cname-- interntet and ph...   \n",
      "4  i GO TO PUT MY ZIPCODE INTO MY SIGN IN ARE AND...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  I'm away from home and cannot verify my MAC ad...    88.0    0.0   \n",
      "1  I changed my user name why can't i move on the...   122.0   20.0   \n",
      "2  i paid my bill on 10/21 but it does not appear...   182.0   30.0   \n",
      "3  I am a subscriber to cname-- interntet and pho...   167.0   92.0   \n",
      "4  i GO TO PUT MY ZIPCODE INTO MY SIGN IN [ARE] A...    84.0    3.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         1.000000        1.0  \n",
      "1         0.836066        0.0  \n",
      "2         0.835165        0.0  \n",
      "3         0.449102        0.0  \n",
      "4         0.964286        0.0  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: all_data_by_threshold.csv\n",
      "   Dataset ID  Group ID  Request ID  MultiIntent  Threshold  \\\n",
      "0           1         1        1483            0          1   \n",
      "1           1         1        2439            0          1   \n",
      "2           1         1        2367            0          1   \n",
      "3           1         1        2467            0          1   \n",
      "4           1         1        2488            0          1   \n",
      "\n",
      "                                    MergedSelections  \\\n",
      "0  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "1  [This links to the latest domestic Air NZ ads,...   \n",
      "2  [The reason of this email is to explain an unf...   \n",
      "3  [Hi. I am 6ft 5 tall and hoping to fly to Japa...   \n",
      "4  [We will be there at lunch time. ]Do they offe...   \n",
      "\n",
      "                                          Unselected  \\\n",
      "0  I would really like to know the criteria which...   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3   Just wondered which airline would give any so...   \n",
      "4      Do they offer lunch or should we eat outside?   \n",
      "\n",
      "                                            Selected   Removed  \n",
      "0  Today Ellemay wrote: I however, like Qantas a...  0.892382  \n",
      "1  This links to the latest domestic Air NZ ads, ...  1.000000  \n",
      "2  The reason of this email is to explain an unfo...  1.000000  \n",
      "3  Hi. I am 6ft 5 tall and hoping to fly to Japan...  0.654167  \n",
      "4                   We will be there at lunch time.   0.415584  \n",
      "\n",
      "Dataset: all_multi_intent.csv\n",
      "   Dataset ID  Group ID  Request ID  \\\n",
      "0           1         1        2047   \n",
      "1           1         1        1997   \n",
      "2           1         1        1999   \n",
      "3           1         1        2003   \n",
      "4           1         1        1549   \n",
      "\n",
      "                                                Text  Annotator 1  \\\n",
      "0  Hi all, I have booked to fly from Australia to...            0   \n",
      "1  If my friend and I are turning 17, but want to...            0   \n",
      "2  Hey All, In May, we'll be flying from YYZto JF...            0   \n",
      "3  Here is a little story for you football fans o...            0   \n",
      "4  Quick question... I've just pre booked my seat...            0   \n",
      "\n",
      "   Annotator 2  Annotator 3  Annotator 4  Annotator 5  Annotator 6  \\\n",
      "0            1            0            1            0            1   \n",
      "1            1            0            1            0            1   \n",
      "2            1            0            0            0            0   \n",
      "3            0            0            0            0            0   \n",
      "4            1            0            1            0            0   \n",
      "\n",
      "   Annotator 7  Annotator 8  \n",
      "0            0            1  \n",
      "1            0            1  \n",
      "2            0            1  \n",
      "3            0            1  \n",
      "4            0            0  \n",
      "\n",
      "Dataset: tagged_selections_by_sentence.csv\n",
      "   Dataset  Partition  SentenceID  Threshold  \\\n",
      "0        1          1        2227          2   \n",
      "1        1          1        2182          2   \n",
      "2        1          1        2191          2   \n",
      "3        1          1        2183          2   \n",
      "4        1          1        2198          2   \n",
      "\n",
      "                                    MergedSelections  \\\n",
      "0  [Just to set the scene... I have a fairly tall...   \n",
      "1  I am flying from Luton to Dalaman (Turkey) nex...   \n",
      "2  BA has won their case in the High Court attack...   \n",
      "3  [My family is flying from Hartford Ct to Honol...   \n",
      "4  I have been advised that the best seating is i...   \n",
      "\n",
      "                                          Unselected  \\\n",
      "0   if we check in online, will this mean we auto...   \n",
      "1  I am flying from Luton to Dalaman (Turkey) nex...   \n",
      "2  BA has won their case in the High Court attack...   \n",
      "3   does anyone know if we are allowed to take ou...   \n",
      "4  I have been advised that the best seating is i...   \n",
      "\n",
      "                                            Selected  Greeting  Backstory  \\\n",
      "0  Just to set the scene... I have a fairly tall ...         0          1   \n",
      "1  We already have allocated seats, so as far as ...         0          1   \n",
      "2                                                NaN         0          0   \n",
      "3  My family is flying from Hartford Ct to Honolu...         0          1   \n",
      "4                                                NaN         0          0   \n",
      "\n",
      "   Justification  Rant  Gratitude  Other  Express Emotion  \n",
      "0              0     0          0      1                0  \n",
      "1              0     0          0      1                0  \n",
      "2              0     0          0      0                0  \n",
      "3              0     0          0      0                0  \n",
      "4              0     0          0      0                0  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set the directory path to the current working directory\n",
    "directory_path = os.getcwd()\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(directory_path)\n",
    "\n",
    "# Filter only CSV files\n",
    "csv_files = [file for file in files if file.endswith('.csv')]\n",
    "\n",
    "# Read and display each CSV file\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(directory_path, csv_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Display the dataset\n",
    "    print(f'\\nDataset: {csv_file}')\n",
    "    print(df.head())  # Display the first few rows of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9b16d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the DataFrame '1_1_align':\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              1             7.0          2.0         1.0       6507.0   \n",
      "1              1             7.0          2.0         1.0       6508.0   \n",
      "2              1             7.0          2.0         1.0       6509.0   \n",
      "3              1             7.0          2.0         1.0       6514.0   \n",
      "4              1             7.0          2.0         1.0       6518.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  What advantage is there in booking directly wi...   \n",
      "1  Hi, Could someone please confirm if CX 884 - H...   \n",
      "2  I will be transiting Dubai soon en route to Oz...   \n",
      "3  Does anyone know where I'd find estimated pric...   \n",
      "4  It's from BA and finds the cheapest BA flight ...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  What advantage is there in booking directly wi...   \n",
      "1  [Hi, ]Could someone please confirm if CX 884 -...   \n",
      "2  [I will be transiting Dubai soon en route to O...   \n",
      "3  Does anyone know where I'd find estimated pric...   \n",
      "4  It's from BA and finds the cheapest BA flight ...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  \\\n",
      "0  What advantage is there in booking directly wi...   242.0  152.0   \n",
      "1  Hi, Could someone please confirm if CX 884 - H...   230.0  134.0   \n",
      "2  I will be transiting Dubai soon en route to Oz...   448.0  175.0   \n",
      "3  Does anyone know where I'd find estimated pric...   274.0   76.0   \n",
      "4  It's from BA and finds the cheapest BA flight ...    89.0    0.0   \n",
      "\n",
      "   Alignment Score  Agreement  \n",
      "0         0.371901        0.0  \n",
      "1         0.417391        0.0  \n",
      "2         0.609375        1.0  \n",
      "3         0.722628        1.0  \n",
      "4         1.000000        1.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List of CSV files\n",
    "csv_files = [\n",
    "    '1_1_align.csv', '1_2_align.csv', '1_3_align.csv', '1_4_align.csv',\n",
    "    '2_1_align.csv', '2_2_align.csv', '2_3_align.csv', '2_4_align.csv',\n",
    "    '3_1_align.csv', '3_2_align.csv', '3_3_align.csv', '3_4_align.csv',\n",
    "    '4_1_align.csv', '4_2_align.csv', '4_3_align.csv', '4_4_align.csv',\n",
    "    '5_1_align.csv', '5_2_align.csv', '5_3_align.csv', '5_4_align.csv',\n",
    "    '6_1_align.csv', '6_2_align.csv', '6_3_align.csv', '6_4_align.csv',\n",
    "    '7_1_align.csv', '7_2_align.csv', '7_3_align.csv', '7_4_align.csv',\n",
    "    '8_1_align.csv', '8_2_align.csv', '8_3_align.csv', '8_4_align.csv',\n",
    "    'all_data_by_threshold.csv', 'all_multi_intent.csv', 'tagged_selections_by_sentence.csv'\n",
    "]\n",
    "\n",
    "# Create a dictionary to store DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Read each CSV file into a DataFrame and store it in the dictionary\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(csv_file)\n",
    "    dataframe_name = os.path.splitext(csv_file)[0]  # Using the file name as the DataFrame name\n",
    "    dataframes[dataframe_name] = pd.read_csv(file_path)\n",
    "\n",
    "# Now, 'dataframes' dictionary contains DataFrames with keys as the file names (without extension)\n",
    "# You can access each DataFrame using dataframes['filename']\n",
    "\n",
    "# Example: Display the first few rows of a DataFrame\n",
    "print(\"First few rows of the DataFrame '1_1_align':\")\n",
    "print(dataframes['1_1_align'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49305370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: C:\\Users\\pc\\Downloads\\rsics_dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current Directory:\", current_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00a1bf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame:\n",
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              1             7.0          2.0         1.0       6507.0   \n",
      "1              1             7.0          2.0         1.0       6508.0   \n",
      "2              1             7.0          2.0         1.0       6509.0   \n",
      "3              1             7.0          2.0         1.0       6514.0   \n",
      "4              1             7.0          2.0         1.0       6518.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  What advantage is there in booking directly wi...   \n",
      "1  Hi, Could someone please confirm if CX 884 - H...   \n",
      "2  I will be transiting Dubai soon en route to Oz...   \n",
      "3  Does anyone know where I'd find estimated pric...   \n",
      "4  It's from BA and finds the cheapest BA flight ...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  What advantage is there in booking directly wi...   \n",
      "1  [Hi, ]Could someone please confirm if CX 884 -...   \n",
      "2  [I will be transiting Dubai soon en route to O...   \n",
      "3  Does anyone know where I'd find estimated pric...   \n",
      "4  It's from BA and finds the cheapest BA flight ...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  ...  \\\n",
      "0  What advantage is there in booking directly wi...   242.0  152.0  ...   \n",
      "1  Hi, Could someone please confirm if CX 884 - H...   230.0  134.0  ...   \n",
      "2  I will be transiting Dubai soon en route to Oz...   448.0  175.0  ...   \n",
      "3  Does anyone know where I'd find estimated pric...   274.0   76.0  ...   \n",
      "4  It's from BA and finds the cheapest BA flight ...    89.0    0.0  ...   \n",
      "\n",
      "                                    MergedSelections  \\\n",
      "0  [Just to set the scene... I have a fairly tall...   \n",
      "1  I am flying from Luton to Dalaman (Turkey) nex...   \n",
      "2  BA has won their case in the High Court attack...   \n",
      "3  [My family is flying from Hartford Ct to Honol...   \n",
      "4  I have been advised that the best seating is i...   \n",
      "\n",
      "                                          Unselected  \\\n",
      "0   if we check in online, will this mean we auto...   \n",
      "1  I am flying from Luton to Dalaman (Turkey) nex...   \n",
      "2  BA has won their case in the High Court attack...   \n",
      "3   does anyone know if we are allowed to take ou...   \n",
      "4  I have been advised that the best seating is i...   \n",
      "\n",
      "                                            Selected  Greeting  Backstory  \\\n",
      "0  Just to set the scene... I have a fairly tall ...       0.0        1.0   \n",
      "1  We already have allocated seats, so as far as ...       0.0        1.0   \n",
      "2                                                NaN       0.0        0.0   \n",
      "3  My family is flying from Hartford Ct to Honolu...       0.0        1.0   \n",
      "4                                                NaN       0.0        0.0   \n",
      "\n",
      "   Justification  Rant Gratitude Other Express Emotion  \n",
      "0            0.0   0.0       0.0   1.0             0.0  \n",
      "1            0.0   0.0       0.0   1.0             0.0  \n",
      "2            0.0   0.0       0.0   0.0             0.0  \n",
      "3            0.0   0.0       0.0   0.0             0.0  \n",
      "4            0.0   0.0       0.0   0.0             0.0  \n",
      "\n",
      "[5 rows x 419 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set the directory path\n",
    "directory_path = \"C:\\\\Users\\\\pc\\\\Downloads\\\\rsics_dataset\"\n",
    "\n",
    "# List all CSV files in the directory\n",
    "csv_files = [file for file in os.listdir(directory_path) if file.endswith(\".csv\")]\n",
    "\n",
    "# Create an empty DataFrame to store the combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Loop through each CSV file and concatenate the data\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(directory_path, csv_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    combined_df = pd.concat([combined_df, df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(\"Combined DataFrame:\")\n",
    "print(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b3e15b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Annotator A ID  Annotator B ID  Parition ID  Corpora ID  Sentence ID  \\\n",
      "0              1             7.0          2.0         1.0       6507.0   \n",
      "1              1             7.0          2.0         1.0       6508.0   \n",
      "2              1             7.0          2.0         1.0       6509.0   \n",
      "3              1             7.0          2.0         1.0       6514.0   \n",
      "4              1             7.0          2.0         1.0       6518.0   \n",
      "\n",
      "                                                Text  \\\n",
      "0  What advantage is there in booking directly wi...   \n",
      "1  Hi, Could someone please confirm if CX 884 - H...   \n",
      "2  I will be transiting Dubai soon en route to Oz...   \n",
      "3  Does anyone know where I'd find estimated pric...   \n",
      "4  It's from BA and finds the cheapest BA flight ...   \n",
      "\n",
      "                                    Annotator A Text  \\\n",
      "0  What advantage is there in booking directly wi...   \n",
      "1  [Hi, ]Could someone please confirm if CX 884 -...   \n",
      "2  [I will be transiting Dubai soon en route to O...   \n",
      "3  Does anyone know where I'd find estimated pric...   \n",
      "4  It's from BA and finds the cheapest BA flight ...   \n",
      "\n",
      "                                    Annotator B Text  Length  Error  ...  \\\n",
      "0  What advantage is there in booking directly wi...   242.0  152.0  ...   \n",
      "1  Hi, Could someone please confirm if CX 884 - H...   230.0  134.0  ...   \n",
      "2  I will be transiting Dubai soon en route to Oz...   448.0  175.0  ...   \n",
      "3  Does anyone know where I'd find estimated pric...   274.0   76.0  ...   \n",
      "4  It's from BA and finds the cheapest BA flight ...    89.0    0.0  ...   \n",
      "\n",
      "   Annotator 8  Partition SentenceID  Greeting  Backstory  Justification  \\\n",
      "0          NaN        NaN        NaN       NaN        NaN            NaN   \n",
      "1          NaN        NaN        NaN       NaN        NaN            NaN   \n",
      "2          NaN        NaN        NaN       NaN        NaN            NaN   \n",
      "3          NaN        NaN        NaN       NaN        NaN            NaN   \n",
      "4          NaN        NaN        NaN       NaN        NaN            NaN   \n",
      "\n",
      "   Rant  Gratitude Other Express Emotion  \n",
      "0   NaN        NaN   NaN             NaN  \n",
      "1   NaN        NaN   NaN             NaN  \n",
      "2   NaN        NaN   NaN             NaN  \n",
      "3   NaN        NaN   NaN             NaN  \n",
      "4   NaN        NaN   NaN             NaN  \n",
      "\n",
      "[5 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set the current directory\n",
    "current_directory = r'C:\\Users\\pc\\Downloads\\rsics_dataset'\n",
    "\n",
    "# List all CSV files in the directory\n",
    "csv_files = [file for file in os.listdir(current_directory) if file.endswith(\".csv\")]\n",
    "\n",
    "# Initialize an empty DataFrame to store combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Read and combine each CSV file\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(current_directory, csv_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Add Dataset ID column if not present\n",
    "    if 'Dataset' not in df.columns:\n",
    "        df['Dataset'] = csv_file.replace('.csv', '')\n",
    "\n",
    "    # Add Group ID column if not present\n",
    "    if 'Group ID' not in df.columns:\n",
    "        df['Group ID'] = 1  # Assuming a default value, you may need to adjust this\n",
    "\n",
    "    # Merge data into the combined DataFrame\n",
    "    combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "print(combined_df.head())\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv(os.path.join(current_directory, 'combined_data.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "204818b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:16: DtypeWarning: Columns (0,5,6,7,12,18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_27844\\498407234.py:30: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set the current directory\n",
    "current_directory = r'C:\\Users\\pc\\Downloads\\rsics_dataset'\n",
    "\n",
    "# List all CSV files in the directory\n",
    "csv_files = [file for file in os.listdir(current_directory) if file.endswith(\".csv\")]\n",
    "\n",
    "# Initialize an empty DataFrame to store combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Read and combine each CSV file\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(current_directory, csv_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Identify common columns\n",
    "    common_columns = set(df.columns).intersection(set(combined_df.columns))\n",
    "\n",
    "    # Add Dataset ID column if not present\n",
    "    if 'Dataset' not in df.columns:\n",
    "        df['Dataset'] = csv_file.replace('.csv', '')\n",
    "\n",
    "    # Add Group ID column if not present\n",
    "    if 'Group ID' not in df.columns:\n",
    "        df['Group ID'] = 1  # Assuming a default value, you may need to adjust this\n",
    "\n",
    "    # Merge data into the combined DataFrame\n",
    "    combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "print(combined_df.head())\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv(os.path.join(current_directory, 'combined_data.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00f0a44f",
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m csv_file \u001b[38;5;129;01min\u001b[39;00m csv_files:\n\u001b[0;32m     15\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(current_directory, csv_file)\n\u001b[1;32m---> 16\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Identify common columns\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     common_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns)\u001b[38;5;241m.\u001b[39mintersection(\u001b[38;5;28mset\u001b[39m(combined_df\u001b[38;5;241m.\u001b[39mcolumns)))\n",
      "File \u001b[1;32m~\\anaconda3\\library\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\library\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\library\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\library\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\library\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\library\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1753\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\library\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:79\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     76\u001b[0m     kwds\u001b[38;5;241m.\u001b[39mpop(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     78\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ensure_dtype_objs(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m---> 79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\library\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:554\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set the current directory\n",
    "current_directory = r'C:\\Users\\pc\\Downloads\\rsics_dataset'\n",
    "\n",
    "# List all CSV files in the directory\n",
    "csv_files = [file for file in os.listdir(current_directory) if file.endswith(\".csv\")]\n",
    "\n",
    "# Initialize an empty DataFrame to store combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Read and combine each CSV file\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(current_directory, csv_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Identify common columns\n",
    "    common_columns = list(set(df.columns).intersection(set(combined_df.columns)))\n",
    "\n",
    "    # Add Dataset ID column if not present\n",
    "    if 'Dataset' not in df.columns:\n",
    "        df['Dataset'] = csv_file.replace('.csv', '')\n",
    "\n",
    "    # Add Group ID column if not present\n",
    "    if 'Group ID' not in df.columns:\n",
    "        df['Group ID'] = 1  # Assuming a default value, you may need to adjust this\n",
    "\n",
    "    # Merge data into the combined DataFrame\n",
    "    combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "print(combined_df.head())\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv(os.path.join(current_directory, 'combined_data.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e5c4f38",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 42) (1285165284.py, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 42\u001b[1;36m\u001b[0m\n\u001b[1;33m    combined_df.to_csv(os.path.join(current_directory, 'combined_data\u001b[0m\n\u001b[1;37m                                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 42)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set the current directory\n",
    "current_directory = r'C:\\Users\\pc\\Downloads\\rsics_dataset'\n",
    "\n",
    "# List all CSV files in the directory\n",
    "csv_files = [file for file in os.listdir(current_directory) if file.endswith(\".csv\")]\n",
    "\n",
    "# Initialize an empty DataFrame to store combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Read and combine each CSV file\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(current_directory, csv_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Identify common columns\n",
    "    common_columns = list(set(df.columns).intersection(set(combined_df.columns)))\n",
    "\n",
    "    # Add Dataset ID column if not present\n",
    "    if 'Dataset' not in df.columns:\n",
    "        df['Dataset'] = csv_file.replace('.csv', '')\n",
    "\n",
    "    # Add Group ID column if not present\n",
    "    if 'Group ID' not in df.columns:\n",
    "        df['Group ID'] = 1  # Assuming a default value, you may need to adjust this\n",
    "\n",
    "    # Print information about the DataFrame being merged\n",
    "    print(f\"Processing: {csv_file}\")\n",
    "    print(f\"Columns in {csv_file}: {df.columns}\")\n",
    "    print(f\"Common columns: {common_columns}\")\n",
    "    print(f\"Number of rows in {csv_file}: {len(df)}\\n\")\n",
    "\n",
    "    # Merge data into the combined DataFrame\n",
    "    combined_df = pd.concat([combined_df, df[common_columns]], ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "print(combined_df.head())\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv(os.path.join(current_directory, 'combined_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b53255b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dataset  Partition  SentenceID  Threshold  \\\n",
      "0        1          1        2227          2   \n",
      "1        1          1        2182          2   \n",
      "2        1          1        2191          2   \n",
      "3        1          1        2183          2   \n",
      "4        1          1        2198          2   \n",
      "\n",
      "                                    MergedSelections  \\\n",
      "0  [Just to set the scene... I have a fairly tall...   \n",
      "1  I am flying from Luton to Dalaman (Turkey) nex...   \n",
      "2  BA has won their case in the High Court attack...   \n",
      "3  [My family is flying from Hartford Ct to Honol...   \n",
      "4  I have been advised that the best seating is i...   \n",
      "\n",
      "                                          Unselected  \\\n",
      "0   if we check in online, will this mean we auto...   \n",
      "1  I am flying from Luton to Dalaman (Turkey) nex...   \n",
      "2  BA has won their case in the High Court attack...   \n",
      "3   does anyone know if we are allowed to take ou...   \n",
      "4  I have been advised that the best seating is i...   \n",
      "\n",
      "                                            Selected  Greeting  Backstory  \\\n",
      "0  Just to set the scene... I have a fairly tall ...         0          1   \n",
      "1  We already have allocated seats, so as far as ...         0          1   \n",
      "2                                                NaN         0          0   \n",
      "3  My family is flying from Hartford Ct to Honolu...         0          1   \n",
      "4                                                NaN         0          0   \n",
      "\n",
      "   Justification  Rant  Gratitude  Other  Express Emotion  \n",
      "0              0     0          0      1                0  \n",
      "1              0     0          0      1                0  \n",
      "2              0     0          0      0                0  \n",
      "3              0     0          0      0                0  \n",
      "4              0     0          0      0                0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Specify the directory path\n",
    "directory_path = \"C:\\\\Users\\\\pc\\\\Downloads\\\\rsics_dataset\"\n",
    "\n",
    "# Build the full path to the CSV file\n",
    "csv_file_path = os.path.join(directory_path, 'tagged_selections_by_sentence.csv')\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "tagged_selections_df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame for verification\n",
    "print(tagged_selections_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c1bf429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       Dataset ID  Group ID  Request ID  \\\n",
       "0              1         1        2047   \n",
       "1              1         1        1997   \n",
       "2              1         1        1999   \n",
       "3              1         1        2003   \n",
       "4              1         1        1549   \n",
       "...          ...       ...         ...   \n",
       "1236           4         2        9770   \n",
       "1237           4         2       10237   \n",
       "1238           4         2       10277   \n",
       "1239           4         2       10409   \n",
       "1240           4         2       10098   \n",
       "\n",
       "                                                   Text  Annotator 1  \\\n",
       "0     Hi all, I have booked to fly from Australia to...            0   \n",
       "1     If my friend and I are turning 17, but want to...            0   \n",
       "2     Hey All, In May, we'll be flying from YYZto JF...            0   \n",
       "3     Here is a little story for you football fans o...            0   \n",
       "4     Quick question... I've just pre booked my seat...            0   \n",
       "...                                                 ...          ...   \n",
       "1236  I can't log onto my wireless router. I got on ...            0   \n",
       "1237  Idon't want my bill to be sent electronically;...            1   \n",
       "1238  I went through the process of logging into cna...            1   \n",
       "1239  Looking to change or cancel are service to sav...            0   \n",
       "1240  I would like to update my contact info and che...            0   \n",
       "\n",
       "      Annotator 2  Annotator 3  Annotator 4  Annotator 5  Annotator 6  \\\n",
       "0               1            0            1            0            1   \n",
       "1               1            0            1            0            1   \n",
       "2               1            0            0            0            0   \n",
       "3               0            0            0            0            0   \n",
       "4               1            0            1            0            0   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "1236            0            0            0            0            0   \n",
       "1237            0            1            0            1            0   \n",
       "1238            0            1            0            0            0   \n",
       "1239            0            0            0            1            0   \n",
       "1240            0            1            0            1            0   \n",
       "\n",
       "      Annotator 7  Annotator 8           Dataset  \n",
       "0               0            1  all_multi_intent  \n",
       "1               0            1  all_multi_intent  \n",
       "2               0            1  all_multi_intent  \n",
       "3               0            1  all_multi_intent  \n",
       "4               0            0  all_multi_intent  \n",
       "...           ...          ...               ...  \n",
       "1236            1            0  all_multi_intent  \n",
       "1237            1            0  all_multi_intent  \n",
       "1238            0            0  all_multi_intent  \n",
       "1239            0            0  all_multi_intent  \n",
       "1240            1            0  all_multi_intent  \n",
       "\n",
       "[1241 rows x 13 columns]>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80b5757c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Dataset  Partition  SentenceID  Threshold  \\\n",
      "0           1          1        2227          2   \n",
      "1           1          1        2182          2   \n",
      "2           1          1        2191          2   \n",
      "3           1          1        2183          2   \n",
      "4           1          1        2198          2   \n",
      "...       ...        ...         ...        ...   \n",
      "6754        4          2       10337          2   \n",
      "6755        4          2       10361          2   \n",
      "6756        4          2       10362          2   \n",
      "6757        4          2       10340          2   \n",
      "6758        4          2       10397          2   \n",
      "\n",
      "                                       MergedSelections  \\\n",
      "0     [Just to set the scene... I have a fairly tall...   \n",
      "1     I am flying from Luton to Dalaman (Turkey) nex...   \n",
      "2     BA has won their case in the High Court attack...   \n",
      "3     [My family is flying from Hartford Ct to Honol...   \n",
      "4     I have been advised that the best seating is i...   \n",
      "...                                                 ...   \n",
      "6754  how can get my new credit card shipped to a di...   \n",
      "6755  with the silver option can the service e suspe...   \n",
      "6756  you all has everything in your displaying acce...   \n",
      "6757  How can i upgrade my tv package to include the...   \n",
      "6758  I have a Vizio Smart TV but can't connect to m...   \n",
      "\n",
      "                                             Unselected  \\\n",
      "0      if we check in online, will this mean we auto...   \n",
      "1     I am flying from Luton to Dalaman (Turkey) nex...   \n",
      "2     BA has won their case in the High Court attack...   \n",
      "3      does anyone know if we are allowed to take ou...   \n",
      "4     I have been advised that the best seating is i...   \n",
      "...                                                 ...   \n",
      "6754  how can get my new credit card shipped to a di...   \n",
      "6755  with the silver option can the service e suspe...   \n",
      "6756  you all has everything in your displaying acce...   \n",
      "6757  How can i upgrade my tv package to include the...   \n",
      "6758  I have a Vizio Smart TV but can't connect to m...   \n",
      "\n",
      "                                               Selected  Greeting  Backstory  \\\n",
      "0     Just to set the scene... I have a fairly tall ...         0          1   \n",
      "1     We already have allocated seats, so as far as ...         0          1   \n",
      "2                                                   NaN         0          0   \n",
      "3     My family is flying from Hartford Ct to Honolu...         0          1   \n",
      "4                                                   NaN         0          0   \n",
      "...                                                 ...       ...        ...   \n",
      "6754                                                NaN         0          0   \n",
      "6755                        when we are out f the area?         0          0   \n",
      "6756                     because I do't understand how.         0          0   \n",
      "6757                                                NaN         0          0   \n",
      "6758                                                NaN         0          0   \n",
      "\n",
      "      Justification  Rant  Gratitude  Other  Express Emotion  \n",
      "0                 0     0          0      1                0  \n",
      "1                 0     0          0      1                0  \n",
      "2                 0     0          0      0                0  \n",
      "3                 0     0          0      0                0  \n",
      "4                 0     0          0      0                0  \n",
      "...             ...   ...        ...    ...              ...  \n",
      "6754              0     0          0      0                0  \n",
      "6755              0     0          0      1                0  \n",
      "6756              0     0          0      1                0  \n",
      "6757              0     0          0      0                0  \n",
      "6758              0     0          0      0                0  \n",
      "\n",
      "[6759 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Specify the directory path\n",
    "directory_path = \"C:\\\\Users\\\\pc\\\\Downloads\\\\rsics_dataset\"\n",
    "\n",
    "# Build the full path to the CSV file\n",
    "csv_file_path = os.path.join(directory_path, 'tagged_selections_by_sentence.csv')\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "tagged_selections_df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(tagged_selections_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8824e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dataset  Partition  SentenceID  Threshold  \\\n",
      "0        1          1        2227          2   \n",
      "1        1          1        2182          2   \n",
      "2        1          1        2191          2   \n",
      "3        1          1        2183          2   \n",
      "4        1          1        2198          2   \n",
      "\n",
      "                                    MergedSelections  \\\n",
      "0  [Just to set the scene... I have a fairly tall...   \n",
      "1  I am flying from Luton to Dalaman (Turkey) nex...   \n",
      "2  BA has won their case in the High Court attack...   \n",
      "3  [My family is flying from Hartford Ct to Honol...   \n",
      "4  I have been advised that the best seating is i...   \n",
      "\n",
      "                                          Unselected  \\\n",
      "0   if we check in online, will this mean we auto...   \n",
      "1  I am flying from Luton to Dalaman (Turkey) nex...   \n",
      "2  BA has won their case in the High Court attack...   \n",
      "3   does anyone know if we are allowed to take ou...   \n",
      "4  I have been advised that the best seating is i...   \n",
      "\n",
      "                                            Selected  Greeting  Backstory  \\\n",
      "0  Just to set the scene... I have a fairly tall ...         0          1   \n",
      "1  We already have allocated seats, so as far as ...         0          1   \n",
      "2                                                NaN         0          0   \n",
      "3  My family is flying from Hartford Ct to Honolu...         0          1   \n",
      "4                                                NaN         0          0   \n",
      "\n",
      "   Justification  Rant  Gratitude  Other  Express Emotion  \n",
      "0              0     0          0      1                0  \n",
      "1              0     0          0      1                0  \n",
      "2              0     0          0      0                0  \n",
      "3              0     0          0      0                0  \n",
      "4              0     0          0      0                0  \n"
     ]
    }
   ],
   "source": [
    "print(tagged_selections_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d6bbfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Dataset  Partition  SentenceID  Threshold  \\\n",
      "6754        4          2       10337          2   \n",
      "6755        4          2       10361          2   \n",
      "6756        4          2       10362          2   \n",
      "6757        4          2       10340          2   \n",
      "6758        4          2       10397          2   \n",
      "\n",
      "                                       MergedSelections  \\\n",
      "6754  how can get my new credit card shipped to a di...   \n",
      "6755  with the silver option can the service e suspe...   \n",
      "6756  you all has everything in your displaying acce...   \n",
      "6757  How can i upgrade my tv package to include the...   \n",
      "6758  I have a Vizio Smart TV but can't connect to m...   \n",
      "\n",
      "                                             Unselected  \\\n",
      "6754  how can get my new credit card shipped to a di...   \n",
      "6755  with the silver option can the service e suspe...   \n",
      "6756  you all has everything in your displaying acce...   \n",
      "6757  How can i upgrade my tv package to include the...   \n",
      "6758  I have a Vizio Smart TV but can't connect to m...   \n",
      "\n",
      "                            Selected  Greeting  Backstory  Justification  \\\n",
      "6754                             NaN         0          0              0   \n",
      "6755     when we are out f the area?         0          0              0   \n",
      "6756  because I do't understand how.         0          0              0   \n",
      "6757                             NaN         0          0              0   \n",
      "6758                             NaN         0          0              0   \n",
      "\n",
      "      Rant  Gratitude  Other  Express Emotion  \n",
      "6754     0          0      0                0  \n",
      "6755     0          0      1                0  \n",
      "6756     0          0      1                0  \n",
      "6757     0          0      0                0  \n",
      "6758     0          0      0                0  \n"
     ]
    }
   ],
   "source": [
    "print(tagged_selections_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3748ac4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dataset ID  Group ID  Request ID  MultiIntent  Threshold  \\\n",
      "0           1         1        1483            0          1   \n",
      "1           1         1        2439            0          1   \n",
      "2           1         1        2367            0          1   \n",
      "3           1         1        2467            0          1   \n",
      "4           1         1        2488            0          1   \n",
      "\n",
      "                                    MergedSelections  \\\n",
      "0  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "1  [This links to the latest domestic Air NZ ads,...   \n",
      "2  [The reason of this email is to explain an unf...   \n",
      "3  [Hi. I am 6ft 5 tall and hoping to fly to Japa...   \n",
      "4  [We will be there at lunch time. ]Do they offe...   \n",
      "\n",
      "                                          Unselected  \\\n",
      "0  I would really like to know the criteria which...   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3   Just wondered which airline would give any so...   \n",
      "4      Do they offer lunch or should we eat outside?   \n",
      "\n",
      "                                            Selected   Removed  \n",
      "0  Today Ellemay wrote: I however, like Qantas a...  0.892382  \n",
      "1  This links to the latest domestic Air NZ ads, ...  1.000000  \n",
      "2  The reason of this email is to explain an unfo...  1.000000  \n",
      "3  Hi. I am 6ft 5 tall and hoping to fly to Japan...  0.654167  \n",
      "4                   We will be there at lunch time.   0.415584  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"C:\\\\Users\\\\pc\\\\Downloads\\\\rsics_dataset\\\\all_data_by_threshold.csv\"\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "all_data_df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(all_data_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cebf483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dataset ID  Group ID  Request ID  MultiIntent  Threshold  \\\n",
      "0           1         1        1483            0          1   \n",
      "1           1         1        2439            0          1   \n",
      "2           1         1        2367            0          1   \n",
      "3           1         1        2467            0          1   \n",
      "4           1         1        2488            0          1   \n",
      "\n",
      "                                    MergedSelections  \\\n",
      "0  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "1  [This links to the latest domestic Air NZ ads,...   \n",
      "2  [The reason of this email is to explain an unf...   \n",
      "3  [Hi. I am 6ft 5 tall and hoping to fly to Japa...   \n",
      "4  [We will be there at lunch time. ]Do they offe...   \n",
      "\n",
      "                                          Unselected  \\\n",
      "0  I would really like to know the criteria which...   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3   Just wondered which airline would give any so...   \n",
      "4      Do they offer lunch or should we eat outside?   \n",
      "\n",
      "                                            Selected   Removed  \n",
      "0  Today Ellemay wrote: I however, like Qantas a...  0.892382  \n",
      "1  This links to the latest domestic Air NZ ads, ...  1.000000  \n",
      "2  The reason of this email is to explain an unfo...  1.000000  \n",
      "3  Hi. I am 6ft 5 tall and hoping to fly to Japan...  0.654167  \n",
      "4                   We will be there at lunch time.   0.415584  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"C:\\\\Users\\\\pc\\\\Downloads\\\\rsics_dataset\\\\all_data_by_threshold.csv\"\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "all_data_df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(all_data_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00878280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dataset ID  Group ID  Request ID  \\\n",
      "0           1         1        2047   \n",
      "1           1         1        1997   \n",
      "2           1         1        1999   \n",
      "3           1         1        2003   \n",
      "4           1         1        1549   \n",
      "\n",
      "                                                Text  Annotator 1  \\\n",
      "0  Hi all, I have booked to fly from Australia to...            0   \n",
      "1  If my friend and I are turning 17, but want to...            0   \n",
      "2  Hey All, In May, we'll be flying from YYZto JF...            0   \n",
      "3  Here is a little story for you football fans o...            0   \n",
      "4  Quick question... I've just pre booked my seat...            0   \n",
      "\n",
      "   Annotator 2  Annotator 3  Annotator 4  Annotator 5  Annotator 6  \\\n",
      "0            1            0            1            0            1   \n",
      "1            1            0            1            0            1   \n",
      "2            1            0            0            0            0   \n",
      "3            0            0            0            0            0   \n",
      "4            1            0            1            0            0   \n",
      "\n",
      "   Annotator 7  Annotator 8  \n",
      "0            0            1  \n",
      "1            0            1  \n",
      "2            0            1  \n",
      "3            0            1  \n",
      "4            0            0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"C:\\\\Users\\\\pc\\\\Downloads\\\\rsics_dataset\\\\all_multi_intent.csv\"\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "all_multi_intent_df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(all_multi_intent_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22430e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dataset  Partition  SentenceID  Threshold  \\\n",
      "0        1          1        2227          2   \n",
      "1        1          1        2182          2   \n",
      "2        1          1        2191          2   \n",
      "3        1          1        2183          2   \n",
      "4        1          1        2198          2   \n",
      "\n",
      "                                    MergedSelections  \\\n",
      "0  [Just to set the scene... I have a fairly tall...   \n",
      "1  I am flying from Luton to Dalaman (Turkey) nex...   \n",
      "2  BA has won their case in the High Court attack...   \n",
      "3  [My family is flying from Hartford Ct to Honol...   \n",
      "4  I have been advised that the best seating is i...   \n",
      "\n",
      "                                          Unselected  \\\n",
      "0   if we check in online, will this mean we auto...   \n",
      "1  I am flying from Luton to Dalaman (Turkey) nex...   \n",
      "2  BA has won their case in the High Court attack...   \n",
      "3   does anyone know if we are allowed to take ou...   \n",
      "4  I have been advised that the best seating is i...   \n",
      "\n",
      "                                            Selected  Greeting  Backstory  \\\n",
      "0  Just to set the scene... I have a fairly tall ...         0          1   \n",
      "1  We already have allocated seats, so as far as ...         0          1   \n",
      "2                                                NaN         0          0   \n",
      "3  My family is flying from Hartford Ct to Honolu...         0          1   \n",
      "4                                                NaN         0          0   \n",
      "\n",
      "   Justification  Rant  Gratitude  Other  Express Emotion  \n",
      "0              0     0          0      1                0  \n",
      "1              0     0          0      1                0  \n",
      "2              0     0          0      0                0  \n",
      "3              0     0          0      0                0  \n",
      "4              0     0          0      0                0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"C:\\\\Users\\\\pc\\\\Downloads\\\\rsics_dataset\\\\tagged_selections_by_sentence.csv\"\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "tagged_selections_df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(tagged_selections_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7297a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in all_data_df: Index(['Dataset ID', 'Group ID', 'Request ID', 'MultiIntent', 'Threshold',\n",
      "       'MergedSelections', 'Unselected', 'Selected', 'Removed'],\n",
      "      dtype='object')\n",
      "Columns in tagged_selections_df: Index(['Dataset ID', 'Group ID', 'SentenceID', 'Threshold', 'MergedSelections',\n",
      "       'Unselected', 'Selected', 'Greeting', 'Backstory', 'Justification',\n",
      "       'Rant', 'Gratitude', 'Other', 'Express Emotion'],\n",
      "      dtype='object')\n",
      "Columns in all_multi_intent_df: Index(['Dataset ID', 'Group ID', 'Request ID', 'Text', 'Annotator 1',\n",
      "       'Annotator 2', 'Annotator 3', 'Annotator 4', 'Annotator 5',\n",
      "       'Annotator 6', 'Annotator 7', 'Annotator 8'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the column names for each dataset\n",
    "print(\"Columns in all_data_df:\", all_data_df.columns)\n",
    "print(\"Columns in tagged_selections_df:\", tagged_selections_df.columns)\n",
    "print(\"Columns in all_multi_intent_df:\", all_multi_intent_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61f257c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dataset ID  Group ID  Request ID  MultiIntent  Threshold  \\\n",
      "0           1         1        1483            0          1   \n",
      "1           1         1        1483            0          2   \n",
      "2           1         1        1483            0          2   \n",
      "3           1         1        1483            0          2   \n",
      "4           1         1        1483            0          2   \n",
      "\n",
      "                                  MergedSelections_x  \\\n",
      "0  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "1  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "2  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "3  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "4  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "\n",
      "                                        Unselected_x  \\\n",
      "0  I would really like to know the criteria which...   \n",
      "1  I would really like to know the criteria which...   \n",
      "2  I would really like to know the criteria which...   \n",
      "3  I would really like to know the criteria which...   \n",
      "4  I would really like to know the criteria which...   \n",
      "\n",
      "                                          Selected_x   Removed  SentenceID  \\\n",
      "0  Today Ellemay wrote: I however, like Qantas a...  0.892382         NaN   \n",
      "1  Today Ellemay wrote: I however, like Qantas a...  0.892382      2227.0   \n",
      "2  Today Ellemay wrote: I however, like Qantas a...  0.892382      2182.0   \n",
      "3  Today Ellemay wrote: I however, like Qantas a...  0.892382      2191.0   \n",
      "4  Today Ellemay wrote: I however, like Qantas a...  0.892382      2183.0   \n",
      "\n",
      "   ... Express Emotion Text Annotator 1  Annotator 2  Annotator 3  \\\n",
      "0  ...             NaN  NaN         NaN          NaN          NaN   \n",
      "1  ...             0.0  NaN         NaN          NaN          NaN   \n",
      "2  ...             0.0  NaN         NaN          NaN          NaN   \n",
      "3  ...             0.0  NaN         NaN          NaN          NaN   \n",
      "4  ...             0.0  NaN         NaN          NaN          NaN   \n",
      "\n",
      "   Annotator 4  Annotator 5  Annotator 6  Annotator 7  Annotator 8  \n",
      "0          NaN          NaN          NaN          NaN          NaN  \n",
      "1          NaN          NaN          NaN          NaN          NaN  \n",
      "2          NaN          NaN          NaN          NaN          NaN  \n",
      "3          NaN          NaN          NaN          NaN          NaN  \n",
      "4          NaN          NaN          NaN          NaN          NaN  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge the first two datasets\n",
    "combined_df = pd.merge(all_data_df, tagged_selections_df, on=['Dataset ID', 'Group ID', 'Threshold'], how='outer')\n",
    "\n",
    "# Merge the result with the third dataset\n",
    "combined_df = pd.merge(combined_df, all_multi_intent_df, on=['Dataset ID', 'Group ID', 'Request ID'], how='outer')\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "print(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4dfc9e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dataset ID  Group ID  Request ID  MultiIntent  Threshold  \\\n",
      "0           1         1        1483            0          1   \n",
      "1           1         1        1483            0          2   \n",
      "2           1         1        1483            0          2   \n",
      "3           1         1        1483            0          2   \n",
      "4           1         1        1483            0          2   \n",
      "\n",
      "                                    MergedSelections  \\\n",
      "0  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "1  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "2  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "3  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "4  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "\n",
      "                                          Unselected  \\\n",
      "0  I would really like to know the criteria which...   \n",
      "1  I would really like to know the criteria which...   \n",
      "2  I would really like to know the criteria which...   \n",
      "3  I would really like to know the criteria which...   \n",
      "4  I would really like to know the criteria which...   \n",
      "\n",
      "                                            Selected   Removed  \\\n",
      "0  Today Ellemay wrote: I however, like Qantas a...  0.892382   \n",
      "1  Today Ellemay wrote: I however, like Qantas a...  0.892382   \n",
      "2  Today Ellemay wrote: I however, like Qantas a...  0.892382   \n",
      "3  Today Ellemay wrote: I however, like Qantas a...  0.892382   \n",
      "4  Today Ellemay wrote: I however, like Qantas a...  0.892382   \n",
      "\n",
      "                                  MergedSelections_y  \\\n",
      "0                                                NaN   \n",
      "1  [Just to set the scene... I have a fairly tall...   \n",
      "2  I am flying from Luton to Dalaman (Turkey) nex...   \n",
      "3  BA has won their case in the High Court attack...   \n",
      "4  [My family is flying from Hartford Ct to Honol...   \n",
      "\n",
      "                                        Unselected_y  \\\n",
      "0                                                NaN   \n",
      "1   if we check in online, will this mean we auto...   \n",
      "2  I am flying from Luton to Dalaman (Turkey) nex...   \n",
      "3  BA has won their case in the High Court attack...   \n",
      "4   does anyone know if we are allowed to take ou...   \n",
      "\n",
      "                                          Selected_y  Greeting  Backstory  \\\n",
      "0                                                NaN       NaN        NaN   \n",
      "1  Just to set the scene... I have a fairly tall ...       0.0        1.0   \n",
      "2  We already have allocated seats, so as far as ...       0.0        1.0   \n",
      "3                                                NaN       0.0        0.0   \n",
      "4  My family is flying from Hartford Ct to Honolu...       0.0        1.0   \n",
      "\n",
      "   Justification  Rant  Gratitude  Other  Express Emotion  \n",
      "0            NaN   NaN        NaN    NaN              NaN  \n",
      "1            0.0   0.0        0.0    1.0              0.0  \n",
      "2            0.0   0.0        0.0    1.0              0.0  \n",
      "3            0.0   0.0        0.0    0.0              0.0  \n",
      "4            0.0   0.0        0.0    0.0              0.0  \n"
     ]
    }
   ],
   "source": [
    "# Rename the columns to remove the '_x' suffix\n",
    "combined_df.rename(columns={'MergedSelections_x': 'MergedSelections',\n",
    "                            'Unselected_x': 'Unselected',\n",
    "                            'Selected_x': 'Selected'}, inplace=True)\n",
    "\n",
    "# Drop the redundant columns\n",
    "combined_df.drop(columns=['SentenceID', 'Text', 'Annotator 1', 'Annotator 2', 'Annotator 3',\n",
    "                          'Annotator 4', 'Annotator 5', 'Annotator 6', 'Annotator 7', 'Annotator 8'],\n",
    "                 inplace=True)\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame\n",
    "print(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a43b452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6783000, 19)\n"
     ]
    }
   ],
   "source": [
    "# Display the number of rows and columns\n",
    "print(combined_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e3df28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dataset ID  Group ID  Request ID  MultiIntent  Threshold  \\\n",
      "0           1         1        1483            0          1   \n",
      "1           1         1        1483            0          2   \n",
      "2           1         1        1483            0          2   \n",
      "3           1         1        1483            0          2   \n",
      "4           1         1        1483            0          2   \n",
      "5           1         1        1483            0          2   \n",
      "6           1         1        1483            0          2   \n",
      "7           1         1        1483            0          2   \n",
      "8           1         1        1483            0          2   \n",
      "9           1         1        1483            0          2   \n",
      "\n",
      "                                    MergedSelections  \\\n",
      "0  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "1  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "2  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "3  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "4  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "5  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "6  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "7  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "8  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "9  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "\n",
      "                                          Unselected  \\\n",
      "0  I would really like to know the criteria which...   \n",
      "1  I would really like to know the criteria which...   \n",
      "2  I would really like to know the criteria which...   \n",
      "3  I would really like to know the criteria which...   \n",
      "4  I would really like to know the criteria which...   \n",
      "5  I would really like to know the criteria which...   \n",
      "6  I would really like to know the criteria which...   \n",
      "7  I would really like to know the criteria which...   \n",
      "8  I would really like to know the criteria which...   \n",
      "9  I would really like to know the criteria which...   \n",
      "\n",
      "                                            Selected   Removed  \\\n",
      "0  Today Ellemay wrote: I however, like Qantas a...  0.892382   \n",
      "1  Today Ellemay wrote: I however, like Qantas a...  0.892382   \n",
      "2  Today Ellemay wrote: I however, like Qantas a...  0.892382   \n",
      "3  Today Ellemay wrote: I however, like Qantas a...  0.892382   \n",
      "4  Today Ellemay wrote: I however, like Qantas a...  0.892382   \n",
      "5  Today Ellemay wrote: I however, like Qantas a...  0.892382   \n",
      "6  Today Ellemay wrote: I however, like Qantas a...  0.892382   \n",
      "7  Today Ellemay wrote: I however, like Qantas a...  0.892382   \n",
      "8  Today Ellemay wrote: I however, like Qantas a...  0.892382   \n",
      "9  Today Ellemay wrote: I however, like Qantas a...  0.892382   \n",
      "\n",
      "                                  MergedSelections_y  \\\n",
      "0                                                NaN   \n",
      "1  [Just to set the scene... I have a fairly tall...   \n",
      "2  I am flying from Luton to Dalaman (Turkey) nex...   \n",
      "3  BA has won their case in the High Court attack...   \n",
      "4  [My family is flying from Hartford Ct to Honol...   \n",
      "5  I have been advised that the best seating is i...   \n",
      "6  Need some suggestions for how to keep my 5yo s...   \n",
      "7  [Hello, ]just wondering which travel insurance...   \n",
      "8  [Hi, Last month I booked a ticket for my wife ...   \n",
      "9  So my husband recently made MM Gold with Ameri...   \n",
      "\n",
      "                                        Unselected_y  \\\n",
      "0                                                NaN   \n",
      "1   if we check in online, will this mean we auto...   \n",
      "2  I am flying from Luton to Dalaman (Turkey) nex...   \n",
      "3  BA has won their case in the High Court attack...   \n",
      "4   does anyone know if we are allowed to take ou...   \n",
      "5  I have been advised that the best seating is i...   \n",
      "6  Need some suggestions for how to keep my 5yo s...   \n",
      "7  just wondering which travel insurance you guys...   \n",
      "8   Her ticket is also booked under Jane Doe. she...   \n",
      "9  So my husband recently made MM Gold with Ameri...   \n",
      "\n",
      "                                          Selected_y  Greeting  Backstory  \\\n",
      "0                                                NaN       NaN        NaN   \n",
      "1  Just to set the scene... I have a fairly tall ...       0.0        1.0   \n",
      "2  We already have allocated seats, so as far as ...       0.0        1.0   \n",
      "3                                                NaN       0.0        0.0   \n",
      "4  My family is flying from Hartford Ct to Honolu...       0.0        1.0   \n",
      "5                                                NaN       0.0        0.0   \n",
      "6  I knew United did not have seat back TVs or a ...       0.0        1.0   \n",
      "7  Hello,  In the fall we had a two week vacation...       1.0        1.0   \n",
      "8  Hi, Last month I booked a ticket for my wife a...       0.0        1.0   \n",
      "9   But Speedbird recently linked me to an AA wik...       0.0        1.0   \n",
      "\n",
      "   Justification  Rant  Gratitude  Other  Express Emotion  \n",
      "0            NaN   NaN        NaN    NaN              NaN  \n",
      "1            0.0   0.0        0.0    1.0              0.0  \n",
      "2            0.0   0.0        0.0    1.0              0.0  \n",
      "3            0.0   0.0        0.0    0.0              0.0  \n",
      "4            0.0   0.0        0.0    0.0              0.0  \n",
      "5            0.0   0.0        0.0    0.0              0.0  \n",
      "6            0.0   0.0        0.0    1.0              0.0  \n",
      "7            0.0   1.0        1.0    0.0              0.0  \n",
      "8            0.0   0.0        0.0    1.0              0.0  \n",
      "9            0.0   0.0        0.0    1.0              0.0  \n"
     ]
    }
   ],
   "source": [
    "# Display the first 10 rows of the DataFrame\n",
    "print(combined_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb968214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after removing duplicates: (6719000, 19)\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows based on all columns\n",
    "duplicate_rows = combined_df[combined_df.duplicated()]\n",
    "\n",
    "# Remove duplicate rows\n",
    "combined_df = combined_df.drop_duplicates()\n",
    "\n",
    "# Check the shape of the DataFrame after removing duplicates\n",
    "print(\"Shape after removing duplicates:\", combined_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fe4e40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_data_by_threshold.csv shape: (32000, 9)\n",
      "tagged_selections_by_sentence.csv shape: (6759, 14)\n",
      "all_multi_intent.csv shape: (1241, 12)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming CSV files are in the current directory\n",
    "all_data_path = 'all_data_by_threshold.csv'\n",
    "tagged_selections_path = 'tagged_selections_by_sentence.csv'\n",
    "all_multi_intent_path = 'all_multi_intent.csv'\n",
    "\n",
    "# Load datasets\n",
    "all_data_df = pd.read_csv(all_data_path)\n",
    "tagged_selections_df = pd.read_csv(tagged_selections_path)\n",
    "all_multi_intent_df = pd.read_csv(all_multi_intent_path)\n",
    "\n",
    "# Display the shapes\n",
    "print(\"all_data_by_threshold.csv shape:\", all_data_df.shape)\n",
    "print(\"tagged_selections_by_sentence.csv shape:\", tagged_selections_df.shape)\n",
    "print(\"all_multi_intent.csv shape:\", all_multi_intent_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13e2d1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame shape after removing duplicates: (32000, 35)\n"
     ]
    }
   ],
   "source": [
    "# Assuming combined_df is the DataFrame after merging the datasets\n",
    "combined_df = pd.concat([all_data_df, tagged_selections_df, all_multi_intent_df], axis=1)\n",
    "\n",
    "# Check for duplicates and remove them\n",
    "combined_df_no_duplicates = combined_df.drop_duplicates()\n",
    "\n",
    "# Display the new shape after removing duplicates\n",
    "print(\"Combined DataFrame shape after removing duplicates:\", combined_df_no_duplicates.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dec7acb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dataset ID  Group ID  Request ID  MultiIntent  Threshold  \\\n",
      "0         1.0       1.0      1483.0          0.0        1.0   \n",
      "1         1.0       1.0      2439.0          0.0        1.0   \n",
      "2         1.0       1.0      2367.0          0.0        1.0   \n",
      "3         1.0       1.0      2467.0          0.0        1.0   \n",
      "4         1.0       1.0      2488.0          0.0        1.0   \n",
      "\n",
      "                                    MergedSelections  \\\n",
      "0  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "1  [This links to the latest domestic Air NZ ads,...   \n",
      "2  [The reason of this email is to explain an unf...   \n",
      "3  [Hi. I am 6ft 5 tall and hoping to fly to Japa...   \n",
      "4  [We will be there at lunch time. ]Do they offe...   \n",
      "\n",
      "                                          Unselected  \\\n",
      "0  I would really like to know the criteria which...   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3   Just wondered which airline would give any so...   \n",
      "4      Do they offer lunch or should we eat outside?   \n",
      "\n",
      "                                            Selected   Removed  Dataset  ...  \\\n",
      "0  Today Ellemay wrote: I however, like Qantas a...  0.892382      NaN  ...   \n",
      "1  This links to the latest domestic Air NZ ads, ...  1.000000      NaN  ...   \n",
      "2  The reason of this email is to explain an unfo...  1.000000      NaN  ...   \n",
      "3  Hi. I am 6ft 5 tall and hoping to fly to Japan...  0.654167      NaN  ...   \n",
      "4                   We will be there at lunch time.   0.415584      NaN  ...   \n",
      "\n",
      "   Express Emotion  Text  Annotator 1  Annotator 2  Annotator 3  Annotator 4  \\\n",
      "0              NaN   NaN          NaN          NaN          NaN          NaN   \n",
      "1              NaN   NaN          NaN          NaN          NaN          NaN   \n",
      "2              NaN   NaN          NaN          NaN          NaN          NaN   \n",
      "3              NaN   NaN          NaN          NaN          NaN          NaN   \n",
      "4              NaN   NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   Annotator 5  Annotator 6  Annotator 7 Annotator 8  \n",
      "0          NaN          NaN          NaN         NaN  \n",
      "1          NaN          NaN          NaN         NaN  \n",
      "2          NaN          NaN          NaN         NaN  \n",
      "3          NaN          NaN          NaN         NaN  \n",
      "4          NaN          NaN          NaN         NaN  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming all_data_df, tagged_selections_df, and all_multi_intent_df are your dataframes\n",
    "\n",
    "# Concatenate the datasets vertically (along rows)\n",
    "combined_df = pd.concat([all_data_df, tagged_selections_df, all_multi_intent_df], axis=0, ignore_index=True)\n",
    "\n",
    "# Print the first few rows of the combined dataframe\n",
    "print(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ade2f1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame shape: (40000, 28)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the combined dataframe\n",
    "print(\"Combined DataFrame shape:\", combined_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1281aaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN counts in each column:\n",
      "Dataset ID           6759\n",
      "Group ID             6759\n",
      "Request ID           6759\n",
      "MultiIntent          8000\n",
      "Threshold            1241\n",
      "MergedSelections     1241\n",
      "Unselected           2073\n",
      "Selected            21297\n",
      "Removed              8000\n",
      "Dataset             33241\n",
      "Partition           33241\n",
      "SentenceID          33241\n",
      "Greeting            33241\n",
      "Backstory           33241\n",
      "Justification       33241\n",
      "Rant                33241\n",
      "Gratitude           33241\n",
      "Other               33241\n",
      "Express Emotion     33241\n",
      "Text                38759\n",
      "Annotator 1         38759\n",
      "Annotator 2         38759\n",
      "Annotator 3         38759\n",
      "Annotator 4         38759\n",
      "Annotator 5         38759\n",
      "Annotator 6         38759\n",
      "Annotator 7         38759\n",
      "Annotator 8         38759\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count NaN values in each column\n",
    "nan_counts = combined_df.isna().sum()\n",
    "\n",
    "# Print the NaN counts\n",
    "print(\"NaN counts in each column:\")\n",
    "print(nan_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ca77e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in combined_df: 28\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of columns in combined_df:\", len(combined_df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37198915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in combined_df: ['Dataset ID', 'Group ID', 'Request ID', 'MultiIntent', 'Threshold', 'MergedSelections', 'Unselected', 'Selected', 'Removed', 'Dataset', 'Partition', 'SentenceID', 'Greeting', 'Backstory', 'Justification', 'Rant', 'Gratitude', 'Other', 'Express Emotion', 'Text', 'Annotator 1', 'Annotator 2', 'Annotator 3', 'Annotator 4', 'Annotator 5', 'Annotator 6', 'Annotator 7', 'Annotator 8']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in combined_df:\", combined_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a7643b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after dropping: Index(['Request ID', 'MultiIntent', 'MergedSelections', 'Unselected',\n",
      "       'Selected', 'Removed', 'Dataset', 'Greeting', 'Backstory',\n",
      "       'Justification', 'Rant', 'Gratitude', 'Other', 'Express Emotion',\n",
      "       'Text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# List of columns to drop\n",
    "columns_to_drop = ['Dataset ID', 'Group ID', 'Threshold', 'Partition', 'SentenceID', 'Annotator 1', 'Annotator 2', 'Annotator 3', 'Annotator 4', 'Annotator 5', 'Annotator 6', 'Annotator 7', 'Annotator 8']\n",
    "\n",
    "# Drop the columns\n",
    "combined_df = combined_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(\"Columns after dropping:\", combined_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c977c957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Request ID  MultiIntent  \\\n",
      "0          1483.0          0.0   \n",
      "1          2439.0          0.0   \n",
      "2          2367.0          0.0   \n",
      "3          2467.0          0.0   \n",
      "4          2488.0          0.0   \n",
      "...           ...          ...   \n",
      "39995      9770.0          NaN   \n",
      "39996     10237.0          NaN   \n",
      "39997     10277.0          NaN   \n",
      "39998     10409.0          NaN   \n",
      "39999     10098.0          NaN   \n",
      "\n",
      "                                        MergedSelections  \\\n",
      "0      [Today Ellemay wrote: I however, like Qantas ...   \n",
      "1      [This links to the latest domestic Air NZ ads,...   \n",
      "2      [The reason of this email is to explain an unf...   \n",
      "3      [Hi. I am 6ft 5 tall and hoping to fly to Japa...   \n",
      "4      [We will be there at lunch time. ]Do they offe...   \n",
      "...                                                  ...   \n",
      "39995                                                NaN   \n",
      "39996                                                NaN   \n",
      "39997                                                NaN   \n",
      "39998                                                NaN   \n",
      "39999                                                NaN   \n",
      "\n",
      "                                              Unselected  \\\n",
      "0      I would really like to know the criteria which...   \n",
      "1                                                    NaN   \n",
      "2                                                    NaN   \n",
      "3       Just wondered which airline would give any so...   \n",
      "4          Do they offer lunch or should we eat outside?   \n",
      "...                                                  ...   \n",
      "39995                                                NaN   \n",
      "39996                                                NaN   \n",
      "39997                                                NaN   \n",
      "39998                                                NaN   \n",
      "39999                                                NaN   \n",
      "\n",
      "                                                Selected   Removed  Dataset  \\\n",
      "0      Today Ellemay wrote: I however, like Qantas a...  0.892382      NaN   \n",
      "1      This links to the latest domestic Air NZ ads, ...  1.000000      NaN   \n",
      "2      The reason of this email is to explain an unfo...  1.000000      NaN   \n",
      "3      Hi. I am 6ft 5 tall and hoping to fly to Japan...  0.654167      NaN   \n",
      "4                       We will be there at lunch time.   0.415584      NaN   \n",
      "...                                                  ...       ...      ...   \n",
      "39995                                                NaN       NaN      NaN   \n",
      "39996                                                NaN       NaN      NaN   \n",
      "39997                                                NaN       NaN      NaN   \n",
      "39998                                                NaN       NaN      NaN   \n",
      "39999                                                NaN       NaN      NaN   \n",
      "\n",
      "       Greeting  Backstory  Justification  Rant  Gratitude  Other  \\\n",
      "0           NaN        NaN            NaN   NaN        NaN    NaN   \n",
      "1           NaN        NaN            NaN   NaN        NaN    NaN   \n",
      "2           NaN        NaN            NaN   NaN        NaN    NaN   \n",
      "3           NaN        NaN            NaN   NaN        NaN    NaN   \n",
      "4           NaN        NaN            NaN   NaN        NaN    NaN   \n",
      "...         ...        ...            ...   ...        ...    ...   \n",
      "39995       NaN        NaN            NaN   NaN        NaN    NaN   \n",
      "39996       NaN        NaN            NaN   NaN        NaN    NaN   \n",
      "39997       NaN        NaN            NaN   NaN        NaN    NaN   \n",
      "39998       NaN        NaN            NaN   NaN        NaN    NaN   \n",
      "39999       NaN        NaN            NaN   NaN        NaN    NaN   \n",
      "\n",
      "       Express Emotion                                               Text  \n",
      "0                  NaN                                                NaN  \n",
      "1                  NaN                                                NaN  \n",
      "2                  NaN                                                NaN  \n",
      "3                  NaN                                                NaN  \n",
      "4                  NaN                                                NaN  \n",
      "...                ...                                                ...  \n",
      "39995              NaN  I can't log onto my wireless router. I got on ...  \n",
      "39996              NaN  Idon't want my bill to be sent electronically;...  \n",
      "39997              NaN  I went through the process of logging into cna...  \n",
      "39998              NaN  Looking to change or cancel are service to sav...  \n",
      "39999              NaN  I would like to update my contact info and che...  \n",
      "\n",
      "[40000 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "print(combined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "84aba29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame shape after dropping columns: (40000, 13)\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['Request ID', 'Dataset']\n",
    "\n",
    "# Drop the columns\n",
    "combined_df = combined_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Print the new shape of the DataFrame\n",
    "print(\"Combined DataFrame shape after dropping columns:\", combined_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b9fe052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       MultiIntent                                   MergedSelections  \\\n",
      "0              0.0  [Today Ellemay wrote: I however, like Qantas ...   \n",
      "1              0.0  [This links to the latest domestic Air NZ ads,...   \n",
      "2              0.0  [The reason of this email is to explain an unf...   \n",
      "3              0.0  [Hi. I am 6ft 5 tall and hoping to fly to Japa...   \n",
      "4              0.0  [We will be there at lunch time. ]Do they offe...   \n",
      "...            ...                                                ...   \n",
      "39995          NaN                                                NaN   \n",
      "39996          NaN                                                NaN   \n",
      "39997          NaN                                                NaN   \n",
      "39998          NaN                                                NaN   \n",
      "39999          NaN                                                NaN   \n",
      "\n",
      "                                              Unselected  \\\n",
      "0      I would really like to know the criteria which...   \n",
      "1                                                    NaN   \n",
      "2                                                    NaN   \n",
      "3       Just wondered which airline would give any so...   \n",
      "4          Do they offer lunch or should we eat outside?   \n",
      "...                                                  ...   \n",
      "39995                                                NaN   \n",
      "39996                                                NaN   \n",
      "39997                                                NaN   \n",
      "39998                                                NaN   \n",
      "39999                                                NaN   \n",
      "\n",
      "                                                Selected   Removed  Greeting  \\\n",
      "0      Today Ellemay wrote: I however, like Qantas a...  0.892382       NaN   \n",
      "1      This links to the latest domestic Air NZ ads, ...  1.000000       NaN   \n",
      "2      The reason of this email is to explain an unfo...  1.000000       NaN   \n",
      "3      Hi. I am 6ft 5 tall and hoping to fly to Japan...  0.654167       NaN   \n",
      "4                       We will be there at lunch time.   0.415584       NaN   \n",
      "...                                                  ...       ...       ...   \n",
      "39995                                                NaN       NaN       NaN   \n",
      "39996                                                NaN       NaN       NaN   \n",
      "39997                                                NaN       NaN       NaN   \n",
      "39998                                                NaN       NaN       NaN   \n",
      "39999                                                NaN       NaN       NaN   \n",
      "\n",
      "       Backstory  Justification  Rant  Gratitude  Other  Express Emotion  \\\n",
      "0            NaN            NaN   NaN        NaN    NaN              NaN   \n",
      "1            NaN            NaN   NaN        NaN    NaN              NaN   \n",
      "2            NaN            NaN   NaN        NaN    NaN              NaN   \n",
      "3            NaN            NaN   NaN        NaN    NaN              NaN   \n",
      "4            NaN            NaN   NaN        NaN    NaN              NaN   \n",
      "...          ...            ...   ...        ...    ...              ...   \n",
      "39995        NaN            NaN   NaN        NaN    NaN              NaN   \n",
      "39996        NaN            NaN   NaN        NaN    NaN              NaN   \n",
      "39997        NaN            NaN   NaN        NaN    NaN              NaN   \n",
      "39998        NaN            NaN   NaN        NaN    NaN              NaN   \n",
      "39999        NaN            NaN   NaN        NaN    NaN              NaN   \n",
      "\n",
      "                                                    Text  \n",
      "0                                                    NaN  \n",
      "1                                                    NaN  \n",
      "2                                                    NaN  \n",
      "3                                                    NaN  \n",
      "4                                                    NaN  \n",
      "...                                                  ...  \n",
      "39995  I can't log onto my wireless router. I got on ...  \n",
      "39996  Idon't want my bill to be sent electronically;...  \n",
      "39997  I went through the process of logging into cna...  \n",
      "39998  Looking to change or cancel are service to sav...  \n",
      "39999  I would like to update my contact info and che...  \n",
      "\n",
      "[40000 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(combined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f71383",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
